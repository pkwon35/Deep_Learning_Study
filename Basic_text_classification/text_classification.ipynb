{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic text classification\n",
    "\n",
    "## 참고 : https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "\n",
    "### [2022년 6월10일 ~ 6월17일]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# 영화 리뷰를 사용한 텍스트 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 예시에서는 영화 리뷰(후기) 텍스트를 가져와서 이 후기는  \"긍정\" (positive) 또는 \"부정\" (negative)로 분류 해볼꺼에요.\n",
    "\n",
    "이 예제는 이진(binary, 두개로 분류) 즉 예측을 둘중 하나의 값으로 분류하는 문제입니다.  예) 긍정 / 부정, 사람이다 / 아니다, 등등 두개의 값으로 많이 사용되는 분류방법입니다.\n",
    "\n",
    "해당 예시에서는 tf.keras 모듈을 사용해서 해볼려고 합니다!\n",
    "\n",
    "그러기 위해서 일단 필요한 모듈을 설치 및 불러와 봐요~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg62Pmz3o83v"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 모듈 설치 및 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 해당 예시에서는 tensorflow  2.8.0 버전을 사용할것입니다.\n",
    "\n",
    "#### 아래 불러오기 함수가 실행이 안되면 아래 pip 코드 실행하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==\"2.8.2\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:40.138081Z",
     "iopub.status.busy": "2020-09-23T07:21:40.137445Z",
     "iopub.status.idle": "2020-09-23T07:21:46.446713Z",
     "shell.execute_reply": "2020-09-23T07:21:46.447247Z"
    },
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.2\n"
     ]
    }
   ],
   "source": [
    "# 필요 모듈 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAsKG535pHep"
   },
   "source": [
    "## IMDB 데이터셋 다운로드\n",
    "\n",
    "IMDB 데이터셋은 텐서플로우에서 쉽게 불러와 사용할 수 있도록 미리 전처리 된 형태에서 제공하고 있어요.\n",
    "\n",
    "어떤 전처리를 해두었을까요?\n",
    "\n",
    "- string에서 숫자로 변환\n",
    "    - 우리가 보통 생각하기에 리뷰 데이터는 \"와 이 영화 진짜 개꿀잼\" 이런식으로 string 형식이겠죠. 하지만, 우리가 사용할 모델은 이런 string 형식이 input으로 들어오면 이해하지 못해요, 왜냐하면 모델은 \"숫자\"를 받아 프로세스 하기 때문이죠!\n",
    "\n",
    "- 숫자로 변환? 근데 어떻게??\n",
    "    - 주어진 string 형식의 정보를 변환해 모델에 넣어주는 방식은 여러가지가 있어요! 해당 예시에서 우리가 변환하는 방식은 간단해요!\n",
    "        - 특정 단어가 유일한 숫자값으로 mapping 되어있는 어휘사전으로 각 string을 숫자로 변화했어요!\n",
    "        - 조금 더 풀어서 얘기하면.. 일단 이번에 분석하고자하는 모든 데이터에 존재하는 모든 unique 단어를 찾아서 각각 다른 숫자를 지정해서 dictionary로 만들어주면 되요!\n",
    "             \n",
    "             {'I': 100,  'tsukino': 52006,  'nunnery': 52007,  'love': 16816, 'vani': 63951, 'woods': 1408, 'spiders': 16115, ... }\n",
    " \n",
    "        - 위와 같은 dictionary가 만들어지고, \"I love spiders\" 를 string -> 숫자로 변환한다면   100,16816,16115    이런식으로 바꿔서 데이터를 사용할 수 있겠죠?\n",
    "\n",
    "#### 아래에서 keras.datasets.imdb 데이터를 불러와봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:46.451714Z",
     "iopub.status.busy": "2020-09-23T07:21:46.451075Z",
     "iopub.status.idle": "2020-09-23T07:21:51.511011Z",
     "shell.execute_reply": "2020-09-23T07:21:51.510277Z"
    },
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb   # keras에 있는 많은 datasets 예시에서 imdb 데이터 셋 object 불러오기\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)     \n",
    "# load_data 함수 사용해서 imdb 데이터의 train / test   데이터와 레이블 각각 불러오기     \n",
    "# num_words = 10000 을 설정하면 전체 데이터넷에서 많이 나타난 unique 한 단어 상위 10000개를 가져와요. 만약 100이라 하면 unique 100개만 가져오겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fawn': 34701,\n",
       " 'tsukino': 52006,\n",
       " 'nunnery': 52007,\n",
       " 'sonja': 16816,\n",
       " 'vani': 63951,\n",
       " 'woods': 1408,\n",
       " 'spiders': 16115,\n",
       " 'hanging': 2345,\n",
       " 'woody': 2289,\n",
       " 'trawling': 52008,\n",
       " \"hold's\": 52009,\n",
       " 'comically': 11307,\n",
       " 'localized': 40830,\n",
       " 'disobeying': 30568,\n",
       " \"'royale\": 52010,\n",
       " \"harpo's\": 40831,\n",
       " 'canet': 52011,\n",
       " 'aileen': 19313,\n",
       " 'acurately': 52012,\n",
       " \"diplomat's\": 52013,\n",
       " 'rickman': 25242,\n",
       " 'arranged': 6746,\n",
       " 'rumbustious': 52014,\n",
       " 'familiarness': 52015,\n",
       " \"spider'\": 52016,\n",
       " 'hahahah': 68804,\n",
       " \"wood'\": 52017,\n",
       " 'transvestism': 40833,\n",
       " \"hangin'\": 34702,\n",
       " 'bringing': 2338,\n",
       " 'seamier': 40834,\n",
       " 'wooded': 34703,\n",
       " 'bravora': 52018,\n",
       " 'grueling': 16817,\n",
       " 'wooden': 1636,\n",
       " 'wednesday': 16818,\n",
       " \"'prix\": 52019,\n",
       " 'altagracia': 34704,\n",
       " 'circuitry': 52020,\n",
       " 'crotch': 11585,\n",
       " 'busybody': 57766,\n",
       " \"tart'n'tangy\": 52021,\n",
       " 'burgade': 14129,\n",
       " 'thrace': 52023,\n",
       " \"tom's\": 11038,\n",
       " 'snuggles': 52025,\n",
       " 'francesco': 29114,\n",
       " 'complainers': 52027,\n",
       " 'templarios': 52125,\n",
       " '272': 40835,\n",
       " '273': 52028,\n",
       " 'zaniacs': 52130,\n",
       " '275': 34706,\n",
       " 'consenting': 27631,\n",
       " 'snuggled': 40836,\n",
       " 'inanimate': 15492,\n",
       " 'uality': 52030,\n",
       " 'bronte': 11926,\n",
       " 'errors': 4010,\n",
       " 'dialogs': 3230,\n",
       " \"yomada's\": 52031,\n",
       " \"madman's\": 34707,\n",
       " 'dialoge': 30585,\n",
       " 'usenet': 52033,\n",
       " 'videodrome': 40837,\n",
       " \"kid'\": 26338,\n",
       " 'pawed': 52034,\n",
       " \"'girlfriend'\": 30569,\n",
       " \"'pleasure\": 52035,\n",
       " \"'reloaded'\": 52036,\n",
       " \"kazakos'\": 40839,\n",
       " 'rocque': 52037,\n",
       " 'mailings': 52038,\n",
       " 'brainwashed': 11927,\n",
       " 'mcanally': 16819,\n",
       " \"tom''\": 52039,\n",
       " 'kurupt': 25243,\n",
       " 'affiliated': 21905,\n",
       " 'babaganoosh': 52040,\n",
       " \"noe's\": 40840,\n",
       " 'quart': 40841,\n",
       " 'kids': 359,\n",
       " 'uplifting': 5034,\n",
       " 'controversy': 7093,\n",
       " 'kida': 21906,\n",
       " 'kidd': 23379,\n",
       " \"error'\": 52041,\n",
       " 'neurologist': 52042,\n",
       " 'spotty': 18510,\n",
       " 'cobblers': 30570,\n",
       " 'projection': 9878,\n",
       " 'fastforwarding': 40842,\n",
       " 'sters': 52043,\n",
       " \"eggar's\": 52044,\n",
       " 'etherything': 52045,\n",
       " 'gateshead': 40843,\n",
       " 'airball': 34708,\n",
       " 'unsinkable': 25244,\n",
       " 'stern': 7180,\n",
       " \"cervi's\": 52046,\n",
       " 'dnd': 40844,\n",
       " 'dna': 11586,\n",
       " 'insecurity': 20598,\n",
       " \"'reboot'\": 52047,\n",
       " 'trelkovsky': 11037,\n",
       " 'jaekel': 52048,\n",
       " 'sidebars': 52049,\n",
       " \"sforza's\": 52050,\n",
       " 'distortions': 17633,\n",
       " 'mutinies': 52051,\n",
       " 'sermons': 30602,\n",
       " '7ft': 40846,\n",
       " 'boobage': 52052,\n",
       " \"o'bannon's\": 52053,\n",
       " 'populations': 23380,\n",
       " 'chulak': 52054,\n",
       " 'mesmerize': 27633,\n",
       " 'quinnell': 52055,\n",
       " 'yahoo': 10307,\n",
       " 'meteorologist': 52057,\n",
       " 'beswick': 42577,\n",
       " 'boorman': 15493,\n",
       " 'voicework': 40847,\n",
       " \"ster'\": 52058,\n",
       " 'blustering': 22922,\n",
       " 'hj': 52059,\n",
       " 'intake': 27634,\n",
       " 'morally': 5621,\n",
       " 'jumbling': 40849,\n",
       " 'bowersock': 52060,\n",
       " \"'porky's'\": 52061,\n",
       " 'gershon': 16821,\n",
       " 'ludicrosity': 40850,\n",
       " 'coprophilia': 52062,\n",
       " 'expressively': 40851,\n",
       " \"india's\": 19500,\n",
       " \"post's\": 34710,\n",
       " 'wana': 52063,\n",
       " 'wang': 5283,\n",
       " 'wand': 30571,\n",
       " 'wane': 25245,\n",
       " 'edgeways': 52321,\n",
       " 'titanium': 34711,\n",
       " 'pinta': 40852,\n",
       " 'want': 178,\n",
       " 'pinto': 30572,\n",
       " 'whoopdedoodles': 52065,\n",
       " 'tchaikovsky': 21908,\n",
       " 'travel': 2103,\n",
       " \"'victory'\": 52066,\n",
       " 'copious': 11928,\n",
       " 'gouge': 22433,\n",
       " \"chapters'\": 52067,\n",
       " 'barbra': 6702,\n",
       " 'uselessness': 30573,\n",
       " \"wan'\": 52068,\n",
       " 'assimilated': 27635,\n",
       " 'petiot': 16116,\n",
       " 'most\\x85and': 52069,\n",
       " 'dinosaurs': 3930,\n",
       " 'wrong': 352,\n",
       " 'seda': 52070,\n",
       " 'stollen': 52071,\n",
       " 'sentencing': 34712,\n",
       " 'ouroboros': 40853,\n",
       " 'assimilates': 40854,\n",
       " 'colorfully': 40855,\n",
       " 'glenne': 27636,\n",
       " 'dongen': 52072,\n",
       " 'subplots': 4760,\n",
       " 'kiloton': 52073,\n",
       " 'chandon': 23381,\n",
       " \"effect'\": 34713,\n",
       " 'snugly': 27637,\n",
       " 'kuei': 40856,\n",
       " 'welcomed': 9092,\n",
       " 'dishonor': 30071,\n",
       " 'concurrence': 52075,\n",
       " 'stoicism': 23382,\n",
       " \"guys'\": 14896,\n",
       " \"beroemd'\": 52077,\n",
       " 'butcher': 6703,\n",
       " \"melfi's\": 40857,\n",
       " 'aargh': 30623,\n",
       " 'playhouse': 20599,\n",
       " 'wickedly': 11308,\n",
       " 'fit': 1180,\n",
       " 'labratory': 52078,\n",
       " 'lifeline': 40859,\n",
       " 'screaming': 1927,\n",
       " 'fix': 4287,\n",
       " 'cineliterate': 52079,\n",
       " 'fic': 52080,\n",
       " 'fia': 52081,\n",
       " 'fig': 34714,\n",
       " 'fmvs': 52082,\n",
       " 'fie': 52083,\n",
       " 'reentered': 52084,\n",
       " 'fin': 30574,\n",
       " 'doctresses': 52085,\n",
       " 'fil': 52086,\n",
       " 'zucker': 12606,\n",
       " 'ached': 31931,\n",
       " 'counsil': 52088,\n",
       " 'paterfamilias': 52089,\n",
       " 'songwriter': 13885,\n",
       " 'shivam': 34715,\n",
       " 'hurting': 9654,\n",
       " 'effects': 299,\n",
       " 'slauther': 52090,\n",
       " \"'flame'\": 52091,\n",
       " 'sommerset': 52092,\n",
       " 'interwhined': 52093,\n",
       " 'whacking': 27638,\n",
       " 'bartok': 52094,\n",
       " 'barton': 8775,\n",
       " 'frewer': 21909,\n",
       " \"fi'\": 52095,\n",
       " 'ingrid': 6192,\n",
       " 'stribor': 30575,\n",
       " 'approporiately': 52096,\n",
       " 'wobblyhand': 52097,\n",
       " 'tantalisingly': 52098,\n",
       " 'ankylosaurus': 52099,\n",
       " 'parasites': 17634,\n",
       " 'childen': 52100,\n",
       " \"jenkins'\": 52101,\n",
       " 'metafiction': 52102,\n",
       " 'golem': 17635,\n",
       " 'indiscretion': 40860,\n",
       " \"reeves'\": 23383,\n",
       " \"inamorata's\": 57781,\n",
       " 'brittannica': 52104,\n",
       " 'adapt': 7916,\n",
       " \"russo's\": 30576,\n",
       " 'guitarists': 48246,\n",
       " 'abbott': 10553,\n",
       " 'abbots': 40861,\n",
       " 'lanisha': 17649,\n",
       " 'magickal': 40863,\n",
       " 'mattter': 52105,\n",
       " \"'willy\": 52106,\n",
       " 'pumpkins': 34716,\n",
       " 'stuntpeople': 52107,\n",
       " 'estimate': 30577,\n",
       " 'ugghhh': 40864,\n",
       " 'gameplay': 11309,\n",
       " \"wern't\": 52108,\n",
       " \"n'sync\": 40865,\n",
       " 'sickeningly': 16117,\n",
       " 'chiara': 40866,\n",
       " 'disturbed': 4011,\n",
       " 'portmanteau': 40867,\n",
       " 'ineffectively': 52109,\n",
       " \"duchonvey's\": 82143,\n",
       " \"nasty'\": 37519,\n",
       " 'purpose': 1285,\n",
       " 'lazers': 52112,\n",
       " 'lightened': 28105,\n",
       " 'kaliganj': 52113,\n",
       " 'popularism': 52114,\n",
       " \"damme's\": 18511,\n",
       " 'stylistics': 30578,\n",
       " 'mindgaming': 52115,\n",
       " 'spoilerish': 46449,\n",
       " \"'corny'\": 52117,\n",
       " 'boerner': 34718,\n",
       " 'olds': 6792,\n",
       " 'bakelite': 52118,\n",
       " 'renovated': 27639,\n",
       " 'forrester': 27640,\n",
       " \"lumiere's\": 52119,\n",
       " 'gaskets': 52024,\n",
       " 'needed': 884,\n",
       " 'smight': 34719,\n",
       " 'master': 1297,\n",
       " \"edie's\": 25905,\n",
       " 'seeber': 40868,\n",
       " 'hiya': 52120,\n",
       " 'fuzziness': 52121,\n",
       " 'genesis': 14897,\n",
       " 'rewards': 12607,\n",
       " 'enthrall': 30579,\n",
       " \"'about\": 40869,\n",
       " \"recollection's\": 52122,\n",
       " 'mutilated': 11039,\n",
       " 'fatherlands': 52123,\n",
       " \"fischer's\": 52124,\n",
       " 'positively': 5399,\n",
       " '270': 34705,\n",
       " 'ahmed': 34720,\n",
       " 'zatoichi': 9836,\n",
       " 'bannister': 13886,\n",
       " 'anniversaries': 52127,\n",
       " \"helm's\": 30580,\n",
       " \"'work'\": 52128,\n",
       " 'exclaimed': 34721,\n",
       " \"'unfunny'\": 52129,\n",
       " '274': 52029,\n",
       " 'feeling': 544,\n",
       " \"wanda's\": 52131,\n",
       " 'dolan': 33266,\n",
       " '278': 52133,\n",
       " 'peacoat': 52134,\n",
       " 'brawny': 40870,\n",
       " 'mishra': 40871,\n",
       " 'worlders': 40872,\n",
       " 'protags': 52135,\n",
       " 'skullcap': 52136,\n",
       " 'dastagir': 57596,\n",
       " 'affairs': 5622,\n",
       " 'wholesome': 7799,\n",
       " 'hymen': 52137,\n",
       " 'paramedics': 25246,\n",
       " 'unpersons': 52138,\n",
       " 'heavyarms': 52139,\n",
       " 'affaire': 52140,\n",
       " 'coulisses': 52141,\n",
       " 'hymer': 40873,\n",
       " 'kremlin': 52142,\n",
       " 'shipments': 30581,\n",
       " 'pixilated': 52143,\n",
       " \"'00s\": 30582,\n",
       " 'diminishing': 18512,\n",
       " 'cinematic': 1357,\n",
       " 'resonates': 14898,\n",
       " 'simplify': 40874,\n",
       " \"nature'\": 40875,\n",
       " 'temptresses': 40876,\n",
       " 'reverence': 16822,\n",
       " 'resonated': 19502,\n",
       " 'dailey': 34722,\n",
       " '2\\x85': 52144,\n",
       " 'treize': 27641,\n",
       " 'majo': 52145,\n",
       " 'kiya': 21910,\n",
       " 'woolnough': 52146,\n",
       " 'thanatos': 39797,\n",
       " 'sandoval': 35731,\n",
       " 'dorama': 40879,\n",
       " \"o'shaughnessy\": 52147,\n",
       " 'tech': 4988,\n",
       " 'fugitives': 32018,\n",
       " 'teck': 30583,\n",
       " \"'e'\": 76125,\n",
       " 'doesn’t': 40881,\n",
       " 'purged': 52149,\n",
       " 'saying': 657,\n",
       " \"martians'\": 41095,\n",
       " 'norliss': 23418,\n",
       " 'dickey': 27642,\n",
       " 'dicker': 52152,\n",
       " \"'sependipity\": 52153,\n",
       " 'padded': 8422,\n",
       " 'ordell': 57792,\n",
       " \"sturges'\": 40882,\n",
       " 'independentcritics': 52154,\n",
       " 'tempted': 5745,\n",
       " \"atkinson's\": 34724,\n",
       " 'hounded': 25247,\n",
       " 'apace': 52155,\n",
       " 'clicked': 15494,\n",
       " \"'humor'\": 30584,\n",
       " \"martino's\": 17177,\n",
       " \"'supporting\": 52156,\n",
       " 'warmongering': 52032,\n",
       " \"zemeckis's\": 34725,\n",
       " 'lube': 21911,\n",
       " 'shocky': 52157,\n",
       " 'plate': 7476,\n",
       " 'plata': 40883,\n",
       " 'sturgess': 40884,\n",
       " \"nerds'\": 40885,\n",
       " 'plato': 20600,\n",
       " 'plath': 34726,\n",
       " 'platt': 40886,\n",
       " 'mcnab': 52159,\n",
       " 'clumsiness': 27643,\n",
       " 'altogether': 3899,\n",
       " 'massacring': 42584,\n",
       " 'bicenntinial': 52160,\n",
       " 'skaal': 40887,\n",
       " 'droning': 14360,\n",
       " 'lds': 8776,\n",
       " 'jaguar': 21912,\n",
       " \"cale's\": 34727,\n",
       " 'nicely': 1777,\n",
       " 'mummy': 4588,\n",
       " \"lot's\": 18513,\n",
       " 'patch': 10086,\n",
       " 'kerkhof': 50202,\n",
       " \"leader's\": 52161,\n",
       " \"'movie\": 27644,\n",
       " 'uncomfirmed': 52162,\n",
       " 'heirloom': 40888,\n",
       " 'wrangle': 47360,\n",
       " 'emotion\\x85': 52163,\n",
       " \"'stargate'\": 52164,\n",
       " 'pinoy': 40889,\n",
       " 'conchatta': 40890,\n",
       " 'broeke': 41128,\n",
       " 'advisedly': 40891,\n",
       " \"barker's\": 17636,\n",
       " 'descours': 52166,\n",
       " 'lots': 772,\n",
       " 'lotr': 9259,\n",
       " 'irs': 9879,\n",
       " 'lott': 52167,\n",
       " 'xvi': 40892,\n",
       " 'irk': 34728,\n",
       " 'irl': 52168,\n",
       " 'ira': 6887,\n",
       " 'belzer': 21913,\n",
       " 'irc': 52169,\n",
       " 'ire': 27645,\n",
       " 'requisites': 40893,\n",
       " 'discipline': 7693,\n",
       " 'lyoko': 52961,\n",
       " 'extend': 11310,\n",
       " 'nature': 873,\n",
       " \"'dickie'\": 52170,\n",
       " 'optimist': 40894,\n",
       " 'lapping': 30586,\n",
       " 'superficial': 3900,\n",
       " 'vestment': 52171,\n",
       " 'extent': 2823,\n",
       " 'tendons': 52172,\n",
       " \"heller's\": 52173,\n",
       " 'quagmires': 52174,\n",
       " 'miyako': 52175,\n",
       " 'moocow': 20601,\n",
       " \"coles'\": 52176,\n",
       " 'lookit': 40895,\n",
       " 'ravenously': 52177,\n",
       " 'levitating': 40896,\n",
       " 'perfunctorily': 52178,\n",
       " 'lookin': 30587,\n",
       " \"lot'\": 40898,\n",
       " 'lookie': 52179,\n",
       " 'fearlessly': 34870,\n",
       " 'libyan': 52181,\n",
       " 'fondles': 40899,\n",
       " 'gopher': 35714,\n",
       " 'wearying': 40901,\n",
       " \"nz's\": 52182,\n",
       " 'minuses': 27646,\n",
       " 'puposelessly': 52183,\n",
       " 'shandling': 52184,\n",
       " 'decapitates': 31268,\n",
       " 'humming': 11929,\n",
       " \"'nother\": 40902,\n",
       " 'smackdown': 21914,\n",
       " 'underdone': 30588,\n",
       " 'frf': 40903,\n",
       " 'triviality': 52185,\n",
       " 'fro': 25248,\n",
       " 'bothers': 8777,\n",
       " \"'kensington\": 52186,\n",
       " 'much': 73,\n",
       " 'muco': 34730,\n",
       " 'wiseguy': 22615,\n",
       " \"richie's\": 27648,\n",
       " 'tonino': 40904,\n",
       " 'unleavened': 52187,\n",
       " 'fry': 11587,\n",
       " \"'tv'\": 40905,\n",
       " 'toning': 40906,\n",
       " 'obese': 14361,\n",
       " 'sensationalized': 30589,\n",
       " 'spiv': 40907,\n",
       " 'spit': 6259,\n",
       " 'arkin': 7364,\n",
       " 'charleton': 21915,\n",
       " 'jeon': 16823,\n",
       " 'boardroom': 21916,\n",
       " 'doubts': 4989,\n",
       " 'spin': 3084,\n",
       " 'hepo': 53083,\n",
       " 'wildcat': 27649,\n",
       " 'venoms': 10584,\n",
       " 'misconstrues': 52191,\n",
       " 'mesmerising': 18514,\n",
       " 'misconstrued': 40908,\n",
       " 'rescinds': 52192,\n",
       " 'prostrate': 52193,\n",
       " 'majid': 40909,\n",
       " 'climbed': 16479,\n",
       " 'canoeing': 34731,\n",
       " 'majin': 52195,\n",
       " 'animie': 57804,\n",
       " 'sylke': 40910,\n",
       " 'conditioned': 14899,\n",
       " 'waddell': 40911,\n",
       " '3\\x85': 52196,\n",
       " 'hyperdrive': 41188,\n",
       " 'conditioner': 34732,\n",
       " 'bricklayer': 53153,\n",
       " 'hong': 2576,\n",
       " 'memoriam': 52198,\n",
       " 'inventively': 30592,\n",
       " \"levant's\": 25249,\n",
       " 'portobello': 20638,\n",
       " 'remand': 52200,\n",
       " 'mummified': 19504,\n",
       " 'honk': 27650,\n",
       " 'spews': 19505,\n",
       " 'visitations': 40912,\n",
       " 'mummifies': 52201,\n",
       " 'cavanaugh': 25250,\n",
       " 'zeon': 23385,\n",
       " \"jungle's\": 40913,\n",
       " 'viertel': 34733,\n",
       " 'frenchmen': 27651,\n",
       " 'torpedoes': 52202,\n",
       " 'schlessinger': 52203,\n",
       " 'torpedoed': 34734,\n",
       " 'blister': 69876,\n",
       " 'cinefest': 52204,\n",
       " 'furlough': 34735,\n",
       " 'mainsequence': 52205,\n",
       " 'mentors': 40914,\n",
       " 'academic': 9094,\n",
       " 'stillness': 20602,\n",
       " 'academia': 40915,\n",
       " 'lonelier': 52206,\n",
       " 'nibby': 52207,\n",
       " \"losers'\": 52208,\n",
       " 'cineastes': 40916,\n",
       " 'corporate': 4449,\n",
       " 'massaging': 40917,\n",
       " 'bellow': 30593,\n",
       " 'absurdities': 19506,\n",
       " 'expetations': 53241,\n",
       " 'nyfiken': 40918,\n",
       " 'mehras': 75638,\n",
       " 'lasse': 52209,\n",
       " 'visability': 52210,\n",
       " 'militarily': 33946,\n",
       " \"elder'\": 52211,\n",
       " 'gainsbourg': 19023,\n",
       " 'hah': 20603,\n",
       " 'hai': 13420,\n",
       " 'haj': 34736,\n",
       " 'hak': 25251,\n",
       " 'hal': 4311,\n",
       " 'ham': 4892,\n",
       " 'duffer': 53259,\n",
       " 'haa': 52213,\n",
       " 'had': 66,\n",
       " 'advancement': 11930,\n",
       " 'hag': 16825,\n",
       " \"hand'\": 25252,\n",
       " 'hay': 13421,\n",
       " 'mcnamara': 20604,\n",
       " \"mozart's\": 52214,\n",
       " 'duffel': 30731,\n",
       " 'haq': 30594,\n",
       " 'har': 13887,\n",
       " 'has': 44,\n",
       " 'hat': 2401,\n",
       " 'hav': 40919,\n",
       " 'haw': 30595,\n",
       " 'figtings': 52215,\n",
       " 'elders': 15495,\n",
       " 'underpanted': 52216,\n",
       " 'pninson': 52217,\n",
       " 'unequivocally': 27652,\n",
       " \"barbara's\": 23673,\n",
       " \"bello'\": 52219,\n",
       " 'indicative': 12997,\n",
       " 'yawnfest': 40920,\n",
       " 'hexploitation': 52220,\n",
       " \"loder's\": 52221,\n",
       " 'sleuthing': 27653,\n",
       " \"justin's\": 32622,\n",
       " \"'ball\": 52222,\n",
       " \"'summer\": 52223,\n",
       " \"'demons'\": 34935,\n",
       " \"mormon's\": 52225,\n",
       " \"laughton's\": 34737,\n",
       " 'debell': 52226,\n",
       " 'shipyard': 39724,\n",
       " 'unabashedly': 30597,\n",
       " 'disks': 40401,\n",
       " 'crowd': 2290,\n",
       " 'crowe': 10087,\n",
       " \"vancouver's\": 56434,\n",
       " 'mosques': 34738,\n",
       " 'crown': 6627,\n",
       " 'culpas': 52227,\n",
       " 'crows': 27654,\n",
       " 'surrell': 53344,\n",
       " 'flowless': 52229,\n",
       " 'sheirk': 52230,\n",
       " \"'three\": 40923,\n",
       " \"peterson'\": 52231,\n",
       " 'ooverall': 52232,\n",
       " 'perchance': 40924,\n",
       " 'bottom': 1321,\n",
       " 'chabert': 53363,\n",
       " 'sneha': 52233,\n",
       " 'inhuman': 13888,\n",
       " 'ichii': 52234,\n",
       " 'ursla': 52235,\n",
       " 'completly': 30598,\n",
       " 'moviedom': 40925,\n",
       " 'raddick': 52236,\n",
       " 'brundage': 51995,\n",
       " 'brigades': 40926,\n",
       " 'starring': 1181,\n",
       " \"'goal'\": 52237,\n",
       " 'caskets': 52238,\n",
       " 'willcock': 52239,\n",
       " \"threesome's\": 52240,\n",
       " \"mosque'\": 52241,\n",
       " \"cover's\": 52242,\n",
       " 'spaceships': 17637,\n",
       " 'anomalous': 40927,\n",
       " 'ptsd': 27655,\n",
       " 'shirdan': 52243,\n",
       " 'obscenity': 21962,\n",
       " 'lemmings': 30599,\n",
       " 'duccio': 30600,\n",
       " \"levene's\": 52244,\n",
       " \"'gorby'\": 52245,\n",
       " \"teenager's\": 25255,\n",
       " 'marshall': 5340,\n",
       " 'honeymoon': 9095,\n",
       " 'shoots': 3231,\n",
       " 'despised': 12258,\n",
       " 'okabasho': 52246,\n",
       " 'fabric': 8289,\n",
       " 'cannavale': 18515,\n",
       " 'raped': 3537,\n",
       " \"tutt's\": 52247,\n",
       " 'grasping': 17638,\n",
       " 'despises': 18516,\n",
       " \"thief's\": 40928,\n",
       " 'rapes': 8926,\n",
       " 'raper': 52248,\n",
       " \"eyre'\": 27656,\n",
       " 'walchek': 52249,\n",
       " \"elmo's\": 23386,\n",
       " 'perfumes': 40929,\n",
       " 'spurting': 21918,\n",
       " \"exposition'\\x85\": 52250,\n",
       " 'denoting': 52251,\n",
       " 'thesaurus': 34740,\n",
       " \"shoot'\": 40930,\n",
       " 'bonejack': 49759,\n",
       " 'simpsonian': 52253,\n",
       " 'hebetude': 30601,\n",
       " \"hallow's\": 34741,\n",
       " 'desperation\\x85': 52254,\n",
       " 'incinerator': 34742,\n",
       " 'congratulations': 10308,\n",
       " 'humbled': 52255,\n",
       " \"else's\": 5924,\n",
       " 'trelkovski': 40845,\n",
       " \"rape'\": 52256,\n",
       " \"'chapters'\": 59386,\n",
       " '1600s': 52257,\n",
       " 'martian': 7253,\n",
       " 'nicest': 25256,\n",
       " 'eyred': 52259,\n",
       " 'passenger': 9457,\n",
       " 'disgrace': 6041,\n",
       " 'moderne': 52260,\n",
       " 'barrymore': 5120,\n",
       " 'yankovich': 52261,\n",
       " 'moderns': 40931,\n",
       " 'studliest': 52262,\n",
       " 'bedsheet': 52263,\n",
       " 'decapitation': 14900,\n",
       " 'slurring': 52264,\n",
       " \"'nunsploitation'\": 52265,\n",
       " \"'character'\": 34743,\n",
       " 'cambodia': 9880,\n",
       " 'rebelious': 52266,\n",
       " 'pasadena': 27657,\n",
       " 'crowne': 40932,\n",
       " \"'bedchamber\": 52267,\n",
       " 'conjectural': 52268,\n",
       " 'appologize': 52269,\n",
       " 'halfassing': 52270,\n",
       " 'paycheque': 57816,\n",
       " 'palms': 20606,\n",
       " \"'islands\": 52271,\n",
       " 'hawked': 40933,\n",
       " 'palme': 21919,\n",
       " 'conservatively': 40934,\n",
       " 'larp': 64007,\n",
       " 'palma': 5558,\n",
       " 'smelling': 21920,\n",
       " 'aragorn': 12998,\n",
       " 'hawker': 52272,\n",
       " 'hawkes': 52273,\n",
       " 'explosions': 3975,\n",
       " 'loren': 8059,\n",
       " \"pyle's\": 52274,\n",
       " 'shootout': 6704,\n",
       " \"mike's\": 18517,\n",
       " \"driscoll's\": 52275,\n",
       " 'cogsworth': 40935,\n",
       " \"britian's\": 52276,\n",
       " 'childs': 34744,\n",
       " \"portrait's\": 52277,\n",
       " 'chain': 3626,\n",
       " 'whoever': 2497,\n",
       " 'puttered': 52278,\n",
       " 'childe': 52279,\n",
       " 'maywether': 52280,\n",
       " 'chair': 3036,\n",
       " \"rance's\": 52281,\n",
       " 'machu': 34745,\n",
       " 'ballet': 4517,\n",
       " 'grapples': 34746,\n",
       " 'summerize': 76152,\n",
       " 'freelance': 30603,\n",
       " \"andrea's\": 52283,\n",
       " '\\x91very': 52284,\n",
       " 'coolidge': 45879,\n",
       " 'mache': 18518,\n",
       " 'balled': 52285,\n",
       " 'grappled': 40937,\n",
       " 'macha': 18519,\n",
       " 'underlining': 21921,\n",
       " 'macho': 5623,\n",
       " 'oversight': 19507,\n",
       " 'machi': 25257,\n",
       " 'verbally': 11311,\n",
       " 'tenacious': 21922,\n",
       " 'windshields': 40938,\n",
       " 'paychecks': 18557,\n",
       " 'jerk': 3396,\n",
       " \"good'\": 11931,\n",
       " 'prancer': 34748,\n",
       " 'prances': 21923,\n",
       " 'olympus': 52286,\n",
       " 'lark': 21924,\n",
       " 'embark': 10785,\n",
       " 'gloomy': 7365,\n",
       " 'jehaan': 52287,\n",
       " 'turaqui': 52288,\n",
       " \"child'\": 20607,\n",
       " 'locked': 2894,\n",
       " 'pranced': 52289,\n",
       " 'exact': 2588,\n",
       " 'unattuned': 52290,\n",
       " 'minute': 783,\n",
       " 'skewed': 16118,\n",
       " 'hodgins': 40940,\n",
       " 'skewer': 34749,\n",
       " 'think\\x85': 52291,\n",
       " 'rosenstein': 38765,\n",
       " 'helmit': 52292,\n",
       " 'wrestlemanias': 34750,\n",
       " 'hindered': 16826,\n",
       " \"martha's\": 30604,\n",
       " 'cheree': 52293,\n",
       " \"pluckin'\": 52294,\n",
       " 'ogles': 40941,\n",
       " 'heavyweight': 11932,\n",
       " 'aada': 82190,\n",
       " 'chopping': 11312,\n",
       " 'strongboy': 61534,\n",
       " 'hegemonic': 41342,\n",
       " 'adorns': 40942,\n",
       " 'xxth': 41346,\n",
       " 'nobuhiro': 34751,\n",
       " 'capitães': 52298,\n",
       " 'kavogianni': 52299,\n",
       " 'antwerp': 13422,\n",
       " 'celebrated': 6538,\n",
       " 'roarke': 52300,\n",
       " 'baggins': 40943,\n",
       " 'cheeseburgers': 31270,\n",
       " 'matras': 52301,\n",
       " \"nineties'\": 52302,\n",
       " \"'craig'\": 52303,\n",
       " 'celebrates': 12999,\n",
       " 'unintentionally': 3383,\n",
       " 'drafted': 14362,\n",
       " 'climby': 52304,\n",
       " '303': 52305,\n",
       " 'oldies': 18520,\n",
       " 'climbs': 9096,\n",
       " 'honour': 9655,\n",
       " 'plucking': 34752,\n",
       " '305': 30074,\n",
       " 'address': 5514,\n",
       " 'menjou': 40944,\n",
       " \"'freak'\": 42592,\n",
       " 'dwindling': 19508,\n",
       " 'benson': 9458,\n",
       " 'white’s': 52307,\n",
       " 'shamelessness': 40945,\n",
       " 'impacted': 21925,\n",
       " 'upatz': 52308,\n",
       " 'cusack': 3840,\n",
       " \"flavia's\": 37567,\n",
       " 'effette': 52309,\n",
       " 'influx': 34753,\n",
       " 'boooooooo': 52310,\n",
       " 'dimitrova': 52311,\n",
       " 'houseman': 13423,\n",
       " 'bigas': 25259,\n",
       " 'boylen': 52312,\n",
       " 'phillipenes': 52313,\n",
       " 'fakery': 40946,\n",
       " \"grandpa's\": 27658,\n",
       " 'darnell': 27659,\n",
       " 'undergone': 19509,\n",
       " 'handbags': 52315,\n",
       " 'perished': 21926,\n",
       " 'pooped': 37778,\n",
       " 'vigour': 27660,\n",
       " 'opposed': 3627,\n",
       " 'etude': 52316,\n",
       " \"caine's\": 11799,\n",
       " 'doozers': 52317,\n",
       " 'photojournals': 34754,\n",
       " 'perishes': 52318,\n",
       " 'constrains': 34755,\n",
       " 'migenes': 40948,\n",
       " 'consoled': 30605,\n",
       " 'alastair': 16827,\n",
       " 'wvs': 52319,\n",
       " 'ooooooh': 52320,\n",
       " 'approving': 34756,\n",
       " 'consoles': 40949,\n",
       " 'disparagement': 52064,\n",
       " 'futureistic': 52322,\n",
       " 'rebounding': 52323,\n",
       " \"'date\": 52324,\n",
       " 'gregoire': 52325,\n",
       " 'rutherford': 21927,\n",
       " 'americanised': 34757,\n",
       " 'novikov': 82196,\n",
       " 'following': 1042,\n",
       " 'munroe': 34758,\n",
       " \"morita'\": 52326,\n",
       " 'christenssen': 52327,\n",
       " 'oatmeal': 23106,\n",
       " 'fossey': 25260,\n",
       " 'livered': 40950,\n",
       " 'listens': 13000,\n",
       " \"'marci\": 76164,\n",
       " \"otis's\": 52330,\n",
       " 'thanking': 23387,\n",
       " 'maude': 16019,\n",
       " 'extensions': 34759,\n",
       " 'ameteurish': 52332,\n",
       " \"commender's\": 52333,\n",
       " 'agricultural': 27661,\n",
       " 'convincingly': 4518,\n",
       " 'fueled': 17639,\n",
       " 'mahattan': 54014,\n",
       " \"paris's\": 40952,\n",
       " 'vulkan': 52336,\n",
       " 'stapes': 52337,\n",
       " 'odysessy': 52338,\n",
       " 'harmon': 12259,\n",
       " 'surfing': 4252,\n",
       " 'halloran': 23494,\n",
       " 'unbelieveably': 49580,\n",
       " \"'offed'\": 52339,\n",
       " 'quadrant': 30607,\n",
       " 'inhabiting': 19510,\n",
       " 'nebbish': 34760,\n",
       " 'forebears': 40953,\n",
       " 'skirmish': 34761,\n",
       " 'ocassionally': 52340,\n",
       " \"'resist\": 52341,\n",
       " 'impactful': 21928,\n",
       " 'spicier': 52342,\n",
       " 'touristy': 40954,\n",
       " \"'football'\": 52343,\n",
       " 'webpage': 40955,\n",
       " 'exurbia': 52345,\n",
       " 'jucier': 52346,\n",
       " 'professors': 14901,\n",
       " 'structuring': 34762,\n",
       " 'jig': 30608,\n",
       " 'overlord': 40956,\n",
       " 'disconnect': 25261,\n",
       " 'sniffle': 82201,\n",
       " 'slimeball': 40957,\n",
       " 'jia': 40958,\n",
       " 'milked': 16828,\n",
       " 'banjoes': 40959,\n",
       " 'jim': 1237,\n",
       " 'workforces': 52348,\n",
       " 'jip': 52349,\n",
       " 'rotweiller': 52350,\n",
       " 'mundaneness': 34763,\n",
       " \"'ninja'\": 52351,\n",
       " \"dead'\": 11040,\n",
       " \"cipriani's\": 40960,\n",
       " 'modestly': 20608,\n",
       " \"professor'\": 52352,\n",
       " 'shacked': 40961,\n",
       " 'bashful': 34764,\n",
       " 'sorter': 23388,\n",
       " 'overpowering': 16120,\n",
       " 'workmanlike': 18521,\n",
       " 'henpecked': 27662,\n",
       " 'sorted': 18522,\n",
       " \"jōb's\": 52354,\n",
       " \"'always\": 52355,\n",
       " \"'baptists\": 34765,\n",
       " 'dreamcatchers': 52356,\n",
       " \"'silence'\": 52357,\n",
       " 'hickory': 21929,\n",
       " 'fun\\x97yet': 52358,\n",
       " 'breakumentary': 52359,\n",
       " 'didn': 15496,\n",
       " 'didi': 52360,\n",
       " 'pealing': 52361,\n",
       " 'dispite': 40962,\n",
       " \"italy's\": 25262,\n",
       " 'instability': 21930,\n",
       " 'quarter': 6539,\n",
       " 'quartet': 12608,\n",
       " 'padmé': 52362,\n",
       " \"'bleedmedry\": 52363,\n",
       " 'pahalniuk': 52364,\n",
       " 'honduras': 52365,\n",
       " 'bursting': 10786,\n",
       " \"pablo's\": 41465,\n",
       " 'irremediably': 52367,\n",
       " 'presages': 40963,\n",
       " 'bowlegged': 57832,\n",
       " 'dalip': 65183,\n",
       " 'entering': 6260,\n",
       " 'newsradio': 76172,\n",
       " 'presaged': 54150,\n",
       " \"giallo's\": 27663,\n",
       " 'bouyant': 40964,\n",
       " 'amerterish': 52368,\n",
       " 'rajni': 18523,\n",
       " 'leeves': 30610,\n",
       " 'macauley': 34767,\n",
       " 'seriously': 612,\n",
       " 'sugercoma': 52369,\n",
       " 'grimstead': 52370,\n",
       " \"'fairy'\": 52371,\n",
       " 'zenda': 30611,\n",
       " \"'twins'\": 52372,\n",
       " 'realisation': 17640,\n",
       " 'highsmith': 27664,\n",
       " 'raunchy': 7817,\n",
       " 'incentives': 40965,\n",
       " 'flatson': 52374,\n",
       " 'snooker': 35097,\n",
       " 'crazies': 16829,\n",
       " 'crazier': 14902,\n",
       " 'grandma': 7094,\n",
       " 'napunsaktha': 52375,\n",
       " 'workmanship': 30612,\n",
       " 'reisner': 52376,\n",
       " \"sanford's\": 61306,\n",
       " '\\x91doña': 52377,\n",
       " 'modest': 6108,\n",
       " \"everything's\": 19153,\n",
       " 'hamer': 40966,\n",
       " \"couldn't'\": 52379,\n",
       " 'quibble': 13001,\n",
       " 'socking': 52380,\n",
       " 'tingler': 21931,\n",
       " 'gutman': 52381,\n",
       " 'lachlan': 40967,\n",
       " 'tableaus': 52382,\n",
       " 'headbanger': 52383,\n",
       " 'spoken': 2847,\n",
       " 'cerebrally': 34768,\n",
       " \"'road\": 23490,\n",
       " 'tableaux': 21932,\n",
       " \"proust's\": 40968,\n",
       " 'periodical': 40969,\n",
       " \"shoveller's\": 52385,\n",
       " 'tamara': 25263,\n",
       " 'affords': 17641,\n",
       " 'concert': 3249,\n",
       " \"yara's\": 87955,\n",
       " 'someome': 52386,\n",
       " 'lingering': 8424,\n",
       " \"abraham's\": 41511,\n",
       " 'beesley': 34769,\n",
       " 'cherbourg': 34770,\n",
       " 'kagan': 28624,\n",
       " 'snatch': 9097,\n",
       " \"miyazaki's\": 9260,\n",
       " 'absorbs': 25264,\n",
       " \"koltai's\": 40970,\n",
       " 'tingled': 64027,\n",
       " 'crossroads': 19511,\n",
       " 'rehab': 16121,\n",
       " 'falworth': 52389,\n",
       " 'sequals': 52390,\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어와 정수 인덱스를 매핑한 딕셔너리\n",
    "word_index = imdb.get_word_index()\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_words 100 하면,   0~99로 각 단어를 변환한다. 즉 max는 99. (그렇다고 각 문서의 가장 큰 값이 99는 아니다. 해당 단어가 해당 리뷰에 없으면 더 작은값이 나옴)\n",
    "\n",
    "(train_data_100, train_labels_100), (test_data_100, test_labels_100) = imdb.load_data(num_words=100)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< num_words = 100 설정했을때 >\n",
      "각 문서에서 가장 큰 값\n",
      "[1, 99, 78, 13, 66, 40, 2, 2, 5, 2, 2, 21, 4, 2, 2, 8, 2, 14, 2, 2, 6, 2, 7, 2, 6, 2, 7, 2, 21, 12, 32, 2, 2, 2, 4, 2, 2, 81, 27, 2, 2, 2, 2, 2, 2, 38, 76, 2, 2, 11, 6, 2, 2, 8, 2, 4, 22, 14, 2, 7, 4, 2, 2, 2, 12, 17, 2, 2, 2, 2, 4, 58, 8, 2, 12, 2, 2, 62, 28, 2, 6, 2, 2]\n",
      "\n",
      "모든 문서에서 가장 큰 값\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(\"< num_words = 100 설정했을때 >\")\n",
    "print(\"각 문서에서 가장 큰 값\")\n",
    "print(max(train_data_100))\n",
    "print()\n",
    "print(\"모든 문서에서 가장 큰 값\")\n",
    "print(max(max(train_data_100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odr-KlzO-lkL"
   },
   "source": [
    "`num_words=10000`은 훈련 데이터에서 가장 많이 등장하는 상위 10,000개의 단어를 선택합니다.\n",
    "\n",
    "데이터 크기를 적당하게 유지하기 위해 드물게 등장하는 단어는 제외하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## 데이터 탐색\n",
    "\n",
    "이 데이터셋의 샘플은 전처리된 정수 배열입니다.\n",
    "\n",
    "    - 이 정수는 영화 리뷰에 나오는 단어를 나타냅니다.\n",
    "\n",
    "레이블(label)은 정수 0 또는 1입니다.\n",
    "\n",
    "    - 0은 부정적인 리뷰이고 1은 긍정적인 리뷰입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnKvHWW4-lkW"
   },
   "source": [
    "리뷰 텍스트는 어휘 사전의 특정 단어를 나타내는 정수로 변환되어 있습니다. 첫 번째 리뷰를 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:51.522456Z",
     "iopub.status.busy": "2020-09-23T07:21:51.521790Z",
     "iopub.status.idle": "2020-09-23T07:21:51.524067Z",
     "shell.execute_reply": "2020-09-23T07:21:51.524506Z"
    },
    "id": "QtTS4kpEpjbi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "\n",
      "unique 한 단어만 확인\n",
      "[   1    2    4    5    6    7    8    9   12   13   14   15   16   17\n",
      "   18   19   21   22   25   26   28   30   32   33   35   36   38   39\n",
      "   43   46   48   50   51   52   56   62   65   66   71   76   77   82\n",
      "   87   88   92   98  100  103  104  106  107  112  113  117  124  130\n",
      "  134  135  141  144  147  150  167  172  173  178  192  194  215  224\n",
      "  226  256  283  284  297  316  317  336  381  385  386  400  407  447\n",
      "  458  469  476  480  515  530  546  619  626  670  723  838  973 1029\n",
      " 1111 1247 1334 1385 1415 1622 1920 2025 2071 2223 3766 3785 3941 4468\n",
      " 4472 4536 4613 5244 5345 5535 5952 7486]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "print()\n",
    "print(\"unique 한 단어만 확인\")\n",
    "print(np.unique(train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습을 진행하기전, 해당 리뷰의 정체를 먼저 확인해봐요!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88584\n",
      "88584\n"
     ]
    }
   ],
   "source": [
    "# word_index 확인하기\n",
    "\n",
    "a=list(word_index.values())\n",
    "\n",
    "a.sort()\n",
    "\n",
    "print(max(a))\n",
    "print(len(a))\n",
    "\n",
    "# 확인해보니 연속적으로 0 ~ 88590 까지 있는 것은 아니다. 2개 정도 비어있는 것으로 확인됨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 불러온 각 단어와 숫자가 매칭되어있는 word_index 딕셔너리를 활용해 변환을 해보겠습니다\n",
    "word_index = imdb.get_word_index()\n",
    "len(word_index)\n",
    "\n",
    "\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}   # 해당 예시에서는 word의 0 , 1 , 2 , 3 으로 <PAD> , <START> , <UNK> ,  <UNUSED>  추가해야합니다.\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])    # 기존 키값으로 단어가 들어있던 딘셔너리를    키값으로 숫자로    키값과 value값을 스위치 해주는 코드에요  예)  {\"I\":10 , \"love\" : 90}  -->  {10 : \"I\" , 90 : \"love\"}\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])    # 여기서 딕셔너리.get() 함수를 이해해보아요!!   dictionary.get(찾고자하는key값, 해당키값 없으면 돌려주는 value)  로 이해하면되요. \n",
    "                                                                        # 즉, reverse_word_index.get(i, '?') 에서   만약 reverse_word_index 안에 i값이 있으면, 해당 value를 돌려주지만, 만약 해당 i값이 존재하지 않으면 ? 를 돌려줍니다.\n",
    "\n",
    "\n",
    "decode_review(train_data[0])\n",
    "\n",
    "\n",
    "# 아래 결과에서 보이는 <UNK> 의 경우, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFP_XKVRp4_S"
   },
   "source": [
    "## 데이터 준비\n",
    "\n",
    "\n",
    "위에서 string을 숫자로 변환하였지만, 신경망에 주입하기 전 몇가지 변환을 더 해줘야합니다!\n",
    "\n",
    "\n",
    "- 리뷰(정수) 리스트형식의 배열은 신경망에 주입하기 전에 텐서로 변환해야합니다!\n",
    "\n",
    "해당 변환 방법에는 몇 가지가 있습니다:\n",
    "\n",
    "\n",
    "- ### 1) 원-핫 인코딩(one-hot encoding)은 정수 배열을 0과 1로 이루어진 벡터로 변환합니다. 예를 들어 배열 [3, 5]을 인덱스 3과 5만 1이고 나머지는 모두 0인 10,000차원 벡터로 변환할 수 있습니다. 그다음 실수 벡터 데이터를 다룰 수 있는 층-Dense 층-을 신경망의 첫 번째 층으로 사용합니다. 이 방법은 `num_words * num_reviews` 크기의 행렬이 필요하기 때문에 메모리를 많이 사용합니다.\n",
    "\n",
    "\n",
    "- ### 2) 정수 배열의 길이가 모두 같도록 패딩(padding)을 추가해 `max_length * num_reviews` 크기의 정수 텐서를 만듭니다. 이런 형태의 텐서를 다룰 수 있는 임베딩(embedding) 층을 신경망의 첫 번째 층으로 사용할 수 있습니다.\n",
    "\n",
    "\n",
    "해당 예시에서는 두번째 방법인 \"정수 배열의 길이가 같도록 패딩(padding)을 추가하겠습니다!\n",
    "\n",
    "\n",
    "영화 리뷰의 길이가 같아야 하므로 [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) 함수를 사용해 길이를 맞추겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 450 129\n"
     ]
    }
   ],
   "source": [
    "# padding을 적용하기전 데이터의 길이를 비교해보겠습니다\n",
    "\n",
    "print(len(train_data[0]),len(train_data[10]),len(train_data[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:51.901032Z",
     "iopub.status.busy": "2020-09-23T07:21:51.900342Z",
     "iopub.status.idle": "2020-09-23T07:21:52.915360Z",
     "shell.execute_reply": "2020-09-23T07:21:52.914520Z"
    },
    "id": "2jQv-omsHurp"
   },
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],  ## 아까 word_index 에서 \"<PAD>\"\" 로 지정한 숫자, 0을 추가하도록 하겠습니다\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VO5MBpyQdipD"
   },
   "source": [
    "샘플의 길이를 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:52.920484Z",
     "iopub.status.busy": "2020-09-23T07:21:52.919787Z",
     "iopub.status.idle": "2020-09-23T07:21:52.922925Z",
     "shell.execute_reply": "2020-09-23T07:21:52.922417Z"
    },
    "id": "USSSBnkE-lky"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 256 256\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]),len(train_data[10]),len(train_data[20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJoxZGyfjT5V"
   },
   "source": [
    "(패딩된) 첫 번째 리뷰 내용을 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:52.927715Z",
     "iopub.status.busy": "2020-09-23T07:21:52.927036Z",
     "iopub.status.idle": "2020-09-23T07:21:52.929853Z",
     "shell.execute_reply": "2020-09-23T07:21:52.929354Z"
    },
    "id": "TG8X9cqi-lk9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "\n",
    "# 보이는 것과 같이 원래 218 였던 길아의 데이터에 0이 추가로 들어간 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## 모델 구성\n",
    "\n",
    "이제 데이터도 모델에 들어갈 준비가 완료됬습니다!!\n",
    "\n",
    "\n",
    "이제 데이터를 넣어줄 모델을 쌓아보죠.\n",
    "\n",
    "\n",
    "신경망은 층(layer)을 쌓아서 만듭니다. 이 구조에서는 두 가지를 결정해야 합니다:\n",
    "\n",
    "1) 모델에서 얼마나 많은 층을 사용할 것인가?\n",
    "2) 각 층에서 얼마나 많은 은닉 유닛(hidden unit)을 사용할 것인가?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 이 예제의 입력 데이터는 단어 인덱스의 배열입니다.\n",
    "- 예측할 레이블은 0 또는 1입니다. (binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:52.935695Z",
     "iopub.status.busy": "2020-09-23T07:21:52.934804Z",
     "iopub.status.idle": "2020-09-23T07:21:54.626430Z",
     "shell.execute_reply": "2020-09-23T07:21:54.626871Z"
    },
    "id": "xpKOoWgu-llD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 17:05:32.233991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.244428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.245799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.248130: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-17 17:05:32.249664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.251073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.252407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.980618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.982050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.983359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-17 17:05:32.984661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38420 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:00:06.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# 입력 크기는 영화 리뷰 데이터셋에 적용된 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16, input_shape=(None,)))   # 해당 레이어를 지나면, 각 단어에서 context를 뽑아내는 과정을 거칩니다. \n",
    "model.add(keras.layers.GlobalAveragePooling1D())                         # Pooling에 대한 개념을 알고 있으면 좋을 것입니다.   https://gaussian37.github.io/dl-concept-global_average_pooling/\n",
    "                                                                        # 그냥 average pooling 1D 개녕 : https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/average-pooling-1d \n",
    "                                                                        # globalAveragePooling1D 개념 : https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/global-average-pooling-1d\n",
    "                                                                        \n",
    "model.add(keras.layers.Dense(16, activation='relu'))                    # relu 함수의 개념 : https://gooopy.tistory.com/55#:~:text=%EB%A0%90%EB%A3%A8%20%ED%95%A8%EC%88%98(Rectified%20Linear%20Unit%2C%20ReLU)&text=%EB%A0%90%EB%A3%A8%20%ED%95%A8%EC%88%98%EB%8A%94%20%EC%9A%B0%EB%A6%AC%20%EB%A7%90%EB%A1%9C,%EC%9D%84%20%EC%B0%A8%EB%8B%A8%ED%95%9C%EB%8B%A4%EB%8A%94%20%EC%9D%98%EB%AF%B8%EB%8B%A4.\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))                  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 16)          160000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PbKQ6mucuKL"
   },
   "source": [
    "층을 순서대로 쌓아 분류기(classifier)를 만듭니다:\n",
    "\n",
    "1. 첫 번째 층은 `Embedding` 층입니다. 이 층은 정수로 인코딩된 단어를 입력 받고 각 단어 인덱스에 해당하는 임베딩 벡터를 찾습니다. 이 벡터는 모델이 훈련되면서 학습됩니다. 이 벡터는 출력 배열에 새로운 차원으로 추가됩니다. 최종 차원은 `(batch, sequence, embedding)`이 됩니다.\n",
    "\n",
    "2. 그다음 `GlobalAveragePooling1D` 층은 `sequence` 차원에 대해 평균을 계산하여 각 샘플에 대해 고정된 길이의 출력 벡터를 반환합니다. 이는 길이가 다른 입력을 다루는 가장 간단한 방법입니다. https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/global-average-pooling-1d\n",
    "\n",
    "3. 이 고정 길이의 출력 벡터는 16개의 은닉 유닛을 가진 완전 연결(fully-connected) 층(`Dense`)을 거칩니다.\n",
    "\n",
    "4. 마지막 층은 하나의 출력 노드(node)를 가진 완전 연결 층입니다. `sigmoid` 활성화 함수를 사용하여 0과 1 사이의 실수를 출력합니다. 이 값은 확률 또는 신뢰도를 나타냅니다.\n",
    "\n",
    "\n",
    "\n",
    "### 위에서 모델을 쌓아주었으니, 이제 해당 모델의 학습을 위해 컴파일 하겠습니다. (컴파일이란 모델을 학습시키기 위한 학습과정을 설정하는 단계)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4EqVWg4-llM"
   },
   "source": [
    "### 컴파일 함수로 \"손실 함수\"와 \"옵티마이저\" 설정하기\n",
    "\n",
    "모델이 훈련하려면 손실 함수(loss function)과 옵티마이저(optimizer)가 필요합니다. 이 예제는 이진 분류 문제이고 모델이 확률을 출력하므로(출력층의 유닛이 하나이고 `sigmoid` 활성화 함수를 사용합니다), `binary_crossentropy` 손실 함수를 사용하겠습니다.\n",
    "\n",
    "binary_crossentropy : 확률 분포 간의 거리를 측정하는 함수. 정답인 타깃 분포와 예측 분포 사이의 거리를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:54.639995Z",
     "iopub.status.busy": "2020-09-23T07:21:54.639227Z",
     "iopub.status.idle": "2020-09-23T07:21:54.647130Z",
     "shell.execute_reply": "2020-09-23T07:21:54.646492Z"
    },
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCWYwkug-llQ"
   },
   "source": [
    "## 검증 세트 만들기\n",
    "\n",
    "모델링을 할때 주어진 데이터를 3가지로 나눠서 보통 진행합니다.\n",
    "\n",
    "- 학습 (train)\n",
    "- 검증 (validation)\n",
    "- 테스트 (test)\n",
    "\n",
    "\n",
    "모델을 훈련하면서 \"학습\" 데이터와 \"검증\" 데이터를 사용합니다. 다만, 모델 학습시 가중치에 영향을 주는 데이터는 오직 \"학습\" 데이터 입니다. 검증 데이터는 단순히 모델이 훈련되면서 해당 모델에 아무런 영향은 주지 않은 검증데이터의 정확도를 확인하기위해 활용됩니다.\n",
    "\n",
    "- 중요) 모델 \"학습\" 데이터를 사용해 학습하며 \"검증\" 데이터로 정확도를 확인하지만, 얼마나 검증 데이터의 정확도를 잘 측정하는지는 학습과정에 아무런 영향을 주지 않습니다. \n",
    "\n",
    "- 그럼 검증데이터와 테스트 데이터는 비슷한 역활을 하는 것일까요?\n",
    "    - 훈련 데이터만을 사용하여 모델을 개발하고 튜닝하는 것이 목표입니다! 이후 테스트 세트를 사용해서 딱 한 번만 정확도를 평가합니다\n",
    "\n",
    "\n",
    "\n",
    "### 원본 훈련 데이터에서 10,000개의 샘플을 떼어내어 검증 데이터 (validation set)를 만들어봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:54.651865Z",
     "iopub.status.busy": "2020-09-23T07:21:54.651213Z",
     "iopub.status.idle": "2020-09-23T07:21:54.653218Z",
     "shell.execute_reply": "2020-09-23T07:21:54.653608Z"
    },
    "id": "-NpcXY9--llS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]\n",
    "\n",
    "print(len(x_val))  # 검증 10000개\n",
    "print(len(partial_x_train))  # 학습 15000개\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## 모델 훈련\n",
    "\n",
    "이 모델을 512개의 샘플로 이루어진 미니배치(mini-batch)에서 40번의 에포크(epoch) 동안 훈련합니다. `x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 40번 반복한다는 뜻입니다. 훈련하는 동안 10,000개의 검증 세트에서 모델의 손실과 정확도를 모니터링합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:21:54.658876Z",
     "iopub.status.busy": "2020-09-23T07:21:54.658250Z",
     "iopub.status.idle": "2020-09-23T07:22:08.874375Z",
     "shell.execute_reply": "2020-09-23T07:22:08.874803Z"
    },
    "id": "tXSGrjWZ-llW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "28/30 [===========================>..] - ETA: 0s - loss: 0.6923 - accuracy: 0.5804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 17:05:44.422931: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 11ms/step - loss: 0.6923 - accuracy: 0.5837 - val_loss: 0.6908 - val_accuracy: 0.6626\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6878 - accuracy: 0.6043 - val_loss: 0.6844 - val_accuracy: 0.6951\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6773 - accuracy: 0.7294 - val_loss: 0.6709 - val_accuracy: 0.7191\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6575 - accuracy: 0.7683 - val_loss: 0.6482 - val_accuracy: 0.7543\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6271 - accuracy: 0.7801 - val_loss: 0.6158 - val_accuracy: 0.7717\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5882 - accuracy: 0.8039 - val_loss: 0.5760 - val_accuracy: 0.7939\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.8264 - val_loss: 0.5327 - val_accuracy: 0.8190\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.8433 - val_loss: 0.4903 - val_accuracy: 0.8305\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.8583 - val_loss: 0.4517 - val_accuracy: 0.8407\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8701 - val_loss: 0.4190 - val_accuracy: 0.8504\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8791 - val_loss: 0.3927 - val_accuracy: 0.8560\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3443 - accuracy: 0.8867 - val_loss: 0.3714 - val_accuracy: 0.8625\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3196 - accuracy: 0.8937 - val_loss: 0.3543 - val_accuracy: 0.8680\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2990 - accuracy: 0.8987 - val_loss: 0.3429 - val_accuracy: 0.8686\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2816 - accuracy: 0.9037 - val_loss: 0.3295 - val_accuracy: 0.8731\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2650 - accuracy: 0.9089 - val_loss: 0.3206 - val_accuracy: 0.8756\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9126 - val_loss: 0.3135 - val_accuracy: 0.8765\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2387 - accuracy: 0.9175 - val_loss: 0.3069 - val_accuracy: 0.8798\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2273 - accuracy: 0.9227 - val_loss: 0.3021 - val_accuracy: 0.8797\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2165 - accuracy: 0.9267 - val_loss: 0.2977 - val_accuracy: 0.8801\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2069 - accuracy: 0.9299 - val_loss: 0.2944 - val_accuracy: 0.8832\n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1975 - accuracy: 0.9337 - val_loss: 0.2915 - val_accuracy: 0.8828\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1894 - accuracy: 0.9372 - val_loss: 0.2895 - val_accuracy: 0.8839\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1812 - accuracy: 0.9399 - val_loss: 0.2883 - val_accuracy: 0.8845\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1736 - accuracy: 0.9451 - val_loss: 0.2876 - val_accuracy: 0.8848\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1665 - accuracy: 0.9479 - val_loss: 0.2869 - val_accuracy: 0.8849\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9493 - val_loss: 0.2866 - val_accuracy: 0.8851\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1535 - accuracy: 0.9524 - val_loss: 0.2862 - val_accuracy: 0.8859\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9549 - val_loss: 0.2870 - val_accuracy: 0.8857\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9571 - val_loss: 0.2883 - val_accuracy: 0.8855\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1367 - accuracy: 0.9588 - val_loss: 0.2891 - val_accuracy: 0.8861\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.9613 - val_loss: 0.2907 - val_accuracy: 0.8850\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1260 - accuracy: 0.9639 - val_loss: 0.2913 - val_accuracy: 0.8857\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9653 - val_loss: 0.2933 - val_accuracy: 0.8850\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.9681 - val_loss: 0.2954 - val_accuracy: 0.8852\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1121 - accuracy: 0.9693 - val_loss: 0.2976 - val_accuracy: 0.8845\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1083 - accuracy: 0.9703 - val_loss: 0.3016 - val_accuracy: 0.8833\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9718 - val_loss: 0.3030 - val_accuracy: 0.8831\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9731 - val_loss: 0.3052 - val_accuracy: 0.8850\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0965 - accuracy: 0.9743 - val_loss: 0.3079 - val_accuracy: 0.8835\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## 모델 평가\n",
    "\n",
    "모델의 성능을 확인해 보죠. 두 개의 값이 반환됩니다. 손실(오차를 나타내는 숫자이므로 낮을수록 좋습니다)과 정확도입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:08.879756Z",
     "iopub.status.busy": "2020-09-23T07:22:08.879054Z",
     "iopub.status.idle": "2020-09-23T07:22:10.410627Z",
     "shell.execute_reply": "2020-09-23T07:22:10.411068Z"
    },
    "id": "zOMKywn4zReN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3269 - accuracy: 0.8731 - 1s/epoch - 2ms/step\n",
      "[0.32689863443374634, 0.8731200098991394]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data,  test_labels, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1iEXVTR0Z2t"
   },
   "source": [
    "이 예제는 매우 단순한 방식을 사용하므로 87% 정도의 정확도를 달성했습니다. 고급 방법을 사용한 모델은 95%에 가까운 정확도를 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KggXVeL-llZ"
   },
   "source": [
    "## 정확도와 손실 그래프 그리기\n",
    "\n",
    "`model.fit()`은 `History` 객체를 반환합니다. 여기에는 훈련하는 동안 일어난 모든 정보가 담긴 딕셔너리(dictionary)가 들어 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:10.415929Z",
     "iopub.status.busy": "2020-09-23T07:22:10.415051Z",
     "iopub.status.idle": "2020-09-23T07:22:10.417656Z",
     "shell.execute_reply": "2020-09-23T07:22:10.418079Z"
    },
    "id": "VcvSXvhp-llb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRKsqL40-lle"
   },
   "source": [
    "네 개의 항목이 있습니다. 훈련과 검증 단계에서 모니터링하는 지표들입니다. 훈련 손실과 검증 손실을 그래프로 그려 보고, 훈련 정확도와 검증 정확도도 그래프로 그려서 비교해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:10.424038Z",
     "iopub.status.busy": "2020-09-23T07:22:10.423349Z",
     "iopub.status.idle": "2020-09-23T07:22:10.732376Z",
     "shell.execute_reply": "2020-09-23T07:22:10.732967Z"
    },
    "id": "nGoYf2Js-lle"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvmElEQVR4nO3deZgU1dXH8e8BQUBAZXFj2Iy4ILLIgAtxzyJCwD3gRCVGDcQVowZjDEQlmyQxRI1BfdVEEjR53xDXqFHcYqKAIgqiIoKOCwwom4AwcN4/bjXTM8zSM9M1vf0+z1NPV1dXV5+pmanT996695q7IyIihatZpgMQEZHMUiIQESlwSgQiIgVOiUBEpMApEYiIFDglAhGRAqdEIGllZo+Z2bnp3jeTzGypmX0lhuO6me0Xrd9uZtelsm8DPqfEzJ5oaJy1HPdYMytN93Gl6e2U6QAk88xsfdLTNsAXwNbo+XfdfXqqx3L3oXHsm+/cfWw6jmNmPYD3gBbuXh4dezqQ8u9QCo8SgeDubRPrZrYUON/d/1V1PzPbKXFxEZH8oaohqVGi6G9mPzCzT4C7zWx3M3vYzMrM7LNovSjpPc+Y2fnR+hgze8HMpkT7vmdmQxu4b08ze87M1pnZv8zsVjO7r4a4U4nxBjP7d3S8J8ysU9LrZ5vZMjNbZWbX1nJ+DjOzT8ysedK2U8xsfrQ+2Mz+Y2arzexjM7vFzFrWcKx7zOzGpOdXRe/5yMzOq7LvMDN71czWmtkHZjYp6eXnosfVZrbezI5InNuk9x9pZrPNbE30eGSq56Y2ZnZQ9P7VZrbAzEYkvXaSmS2MjvmhmV0Zbe8U/X5Wm9mnZva8mem61MR0wqUuewEdgO7AhYS/mbuj592AjcAttbz/MOAtoBPwS+AuM7MG7Ptn4GWgIzAJOLuWz0wlxrOAbwN7AC2BxIWpN/D76Pj7RJ9XRDXc/SXgc+D4Ksf9c7S+FRgf/TxHACcA36slbqIYTozi+SrQC6jaPvE5cA6wGzAMGGdmJ0evHR097ububd39P1WO3QF4BJga/Wy/Bh4xs45VfoYdzk0dMbcAHgKeiN53CTDdzA6IdrmLUM3YDugDPB1t/z5QCnQG9gR+CGjcmyamRCB12QZMdPcv3H2ju69y9/919w3uvg6YDBxTy/uXufsd7r4VuBfYm/APn/K+ZtYNGAT82N03u/sLwIM1fWCKMd7t7m+7+0bgAaB/tP104GF3f87dvwCui85BTf4CjAYws3bASdE23H2uu//X3cvdfSnwh2riqM6ZUXxvuPvnhMSX/PM94+6vu/s2d58ffV4qx4WQON5x9z9Fcf0FWAR8I2mfms5NbQ4H2gI/j35HTwMPE50bYAvQ28zau/tn7v5K0va9ge7uvsXdn3cNgNbklAikLmXuvinxxMzamNkfoqqTtYSqiN2Sq0eq+CSx4u4botW29dx3H+DTpG0AH9QUcIoxfpK0viEppn2Sjx1diFfV9FmEb/+nmtnOwKnAK+6+LIpj/6ja45Mojp8SSgd1qRQDsKzKz3eYmc2Kqr7WAGNTPG7i2MuqbFsGdEl6XtO5qTNmd09OmsnHPY2QJJeZ2bNmdkS0/SZgMfCEmS0xswmp/RiSTkoEUpeq386+DxwAHObu7amoiqipuicdPgY6mFmbpG1da9m/MTF+nHzs6DM71rSzuy8kXPCGUrlaCEIV0yKgVxTHDxsSA6F6K9mfCSWiru6+K3B70nHr+jb9EaHKLFk34MMU4qrruF2r1O9vP667z3b3kYRqo5mEkgbuvs7dv+/u+wIjgCvM7IRGxiL1pEQg9dWOUOe+Oqpvnhj3B0bfsOcAk8ysZfRt8hu1vKUxMf4NGG5mX44adq+n7v+TPwOXERLOX6vEsRZYb2YHAuNSjOEBYIyZ9Y4SUdX42xFKSJvMbDAhASWUEaqy9q3h2I8C+5vZWWa2k5l9E+hNqMZpjJcIpYerzayFmR1L+B3NiH5nJWa2q7tvIZyTbQBmNtzM9ovagtYQ2lVqq4qTGCgRSH3dDLQGVgL/Bf7ZRJ9bQmhwXQXcCNxP6O9QnZtpYIzuvgC4iHBx/xj4jNCYWZtEHf3T7r4yafuVhIv0OuCOKOZUYngs+hmeJlSbPF1ll+8B15vZOuDHRN+uo/duILSJ/Du6E+fwKsdeBQwnlJpWAVcDw6vEXW/uvplw4R9KOO+3Aee4+6Jol7OBpVEV2VjC7xNCY/i/gPXAf4Db3H1WY2KR+jO1y0guMrP7gUXuHnuJRCTfqUQgOcHMBpnZl8ysWXR75UhCXbOINJJ6Fkuu2Av4P0LDbSkwzt1fzWxIIvlBVUMiIgVOVUMiIgUu56qGOnXq5D169Mh0GCIiOWXu3Lkr3b1zda/lXCLo0aMHc+bMyXQYIiI5xcyq9ijfTlVDIiIFTolARKTAKRGIiBS4WNsIoo4/vwWaA3e6+8+rvP4b4LjoaRtgD3ffLc6YRKT+tmzZQmlpKZs2bap7Z8moVq1aUVRURIsWLVJ+T2yJIBry91bC5BqlwGwzezAarREAdx+ftP8lwIC44hGRhistLaVdu3b06NGDmucVkkxzd1atWkVpaSk9e/ZM+X1xVg0NBha7+5JoQKoZhGEBajKaaEKPdJs+HXr0gGbNwuN0TeMtUi+bNm2iY8eOSgJZzszo2LFjvUtucSaCLlSeXKOUypNfbGdm3YGe7DjKYuL1C81sjpnNKSsrq1cQ06fDhRfCsmXgHh4vvFDJQKS+lARyQ0N+T9nSWDwK+Fs0ReEO3H2auxe7e3HnztX2h6jRtdfChg2Vt23YELYnqMQgIoUszkTwIZVnWSqi5lmQRhFTtdD771e/PVFCUIlBJPutWrWK/v37079/f/baay+6dOmy/fnmzZtrfe+cOXO49NJL6/yMI488Mi2xPvPMMwwfPjwtx2oqcSaC2UAvM+sZzfQ0imomHI9mbtqdMClF2nWrOslfkq5d4bvfrbvEICL1k+5SdseOHZk3bx7z5s1j7NixjB8/fvvzli1bUl5eXuN7i4uLmTp1ap2f8eKLLzYuyBwWWyJw93LgYuBx4E3gAXdfYGbXm9mIpF1HATM8pmFQJ0+GNm0qb2vVCr7zHTjiCPj88+rfl1ySUNWRSOqaqpQ9ZswYxo4dy2GHHcbVV1/Nyy+/zBFHHMGAAQM48sgjeeutt4DK39AnTZrEeeedx7HHHsu+++5bKUG0bdt2+/7HHnssp59+OgceeCAlJSUkLk+PPvooBx54IAMHDuTSSy+t85v/p59+ysknn0zfvn05/PDDmT9/PgDPPvvs9hLNgAEDWLduHR9//DFHH300/fv3p0+fPjz//PPpPWG1cfecWgYOHOj1dd997t27u5uFx/vuq3itWzf38OdaeSkqqnhvmzaVX2vTpvIxRPLdwoULU963e/fq/6e6d09PLBMnTvSbbrrJzz33XB82bJiXl5e7u/uaNWt8y5Yt7u7+5JNP+qmnnuru7rNmzfJhw4Ztf+8RRxzhmzZt8rKyMu/QoYNv3rzZ3d132WWX7fu3b9/eP/jgA9+6dasffvjh/vzzz/vGjRu9qKjIlyxZ4u7uo0aN2n7cZMmfd/HFF/ukSZPc3f2pp57yfv36ubv78OHD/YUXXnB393Xr1vmWLVt8ypQpfuONN7q7e3l5ua9du7bB56i63xcwx2u4rmZLY3GsSkpg6VLYti08lpRUvPbTn+5YYgBYuRJ+/nP44Q9VdSRSHzW1y9W0vTHOOOMMmjdvDsCaNWs444wz6NOnD+PHj2fBggXVvmfYsGHsvPPOdOrUiT322IPly5fvsM/gwYMpKiqiWbNm9O/fn6VLl7Jo0SL23Xff7ffnjx49us74XnjhBc4++2wAjj/+eFatWsXatWsZMmQIV1xxBVOnTmX16tXstNNODBo0iLvvvptJkybx+uuv065du4aelnoriERQm5ISmDYNuncHs/A4ZQp87WtwzTVN+0ctkg9qaperrb2uoXbZZZft69dddx3HHXccb7zxBg899FCN99LvvPPO29ebN29ebftCKvs0xoQJE7jzzjvZuHEjQ4YMYdGiRRx99NE899xzdOnShTFjxvDHP/4xrZ9Zm4JPBLBjieH734d//AOefBJq6qUdxx+1SD6orl2uTZuwPU5r1qyhS5fQVemee+5J+/EPOOAAlixZwtKlSwG4//7763zPUUcdxfSoceSZZ56hU6dOtG/fnnfffZdDDjmEH/zgBwwaNIhFixaxbNky9txzTy644ALOP/98XnnllbT/DDVRIqjFV74Cd965YzJoij9qkVxVXSl72rTKVbJxuPrqq7nmmmsYMGBA2r/BA7Ru3ZrbbruNE088kYEDB9KuXTt23XXXWt8zadIk5s6dS9++fZkwYQL33nsvADfffDN9+vShb9++tGjRgqFDh/LMM8/Qr18/BgwYwP33389ll12W9p+hJjk3Z3FxcbE39cQ006fDD34AH34Y/rB/9CO4/vomDUEko958800OOuigTIeRcevXr6dt27a4OxdddBG9evVi/Pjxdb+xiVX3+zKzue5eXN3+KhGkoKQESkvDsv/+8KtfwVNPVbyu20tFCsMdd9xB//79Ofjgg1mzZg3f/e53Mx1SWqhEUE/Ll4cqo3fegb//HT79NNwjnXxnUZs2TVMUFmkqKhHkFpUIYrbnnjBrFhx8MIwcCePH6/ZSEcltSgQN0KlTqBoaOBBqGgxVt5eKSK5QImig3XaDJ56ApNuNK9HtpSKSK5QIGqFdO7jtttBInEy3l4pILlEiaKTzzgt9DRIlg332UUOxSLodd9xxPP7445W23XzzzYwbN67G9xx77LEkbiw56aSTWL169Q77TJo0iSlTptT62TNnzmThwu0z7PLjH/+Yf/3rX/WIvnrZNFy1EkEafPvb8PbbobqoSxc444xMRySSX0aPHs2MGTMqbZsxY0ZK4/1AGDV0t912a9BnV00E119/PV/5ylcadKxspUSQJt26hZLB7Nlw3XWZjkYkv5x++uk88sgj2yehWbp0KR999BFHHXUU48aNo7i4mIMPPpiJEydW+/4ePXqwcuVKACZPnsz+++/Pl7/85e1DVUPoIzBo0CD69evHaaedxoYNG3jxxRd58MEHueqqq+jfvz/vvvsuY8aM4W9/+xsATz31FAMGDOCQQw7hvPPO44svvtj+eRMnTuTQQw/lkEMOYdGiRbX+fJkernqnRh9BtjvttDDRzS9/CSecEAauE8k3l18O8+al95j9+8PNN9f8eocOHRg8eDCPPfYYI0eOZMaMGZx55pmYGZMnT6ZDhw5s3bqVE044gfnz59O3b99qjzN37lxmzJjBvHnzKC8v59BDD2XgwIEAnHrqqVxwwQUA/OhHP+Kuu+7ikksuYcSIEQwfPpzTTz+90rE2bdrEmDFjeOqpp9h///0555xz+P3vf8/ll18OQKdOnXjllVe47bbbmDJlCnfeeWeNP9/EiRMZMGAAM2fO5Omnn+acc85h3rx5TJkyhVtvvZUhQ4awfv16WrVqxbRp0/j617/Otddey9atW9lQ9f71BlCJIM1+/Wvo3RvOOQdWrAjb1PNYpPGSq4eSq4UeeOABDj30UAYMGMCCBQsqVeNU9fzzz3PKKafQpk0b2rdvz4gRFXNkvfHGGxx11FEccsghTJ8+vcZhrBPeeustevbsyf777w/Aueeey3PPPbf99VNPPRWAgQMHbh+oriaZHq5aJYI0a9MGZsyAQYPg3HPhrLNg7NiKTmeJ2ZpADcqSm2r75h6nkSNHMn78eF555RU2bNjAwIEDee+995gyZQqzZ89m9913Z8yYMTUOP12XMWPGMHPmTPr168c999zDM88806h4E0NZN2YY6wkTJjBs2DAeffRRhgwZwuOPP759uOpHHnmEMWPGcMUVV3DOOec0KlaVCGJwyCGhZPDPf8Jll6nnsUg6tG3bluOOO47zzjtve2lg7dq17LLLLuy6664sX76cxx57rNZjHH300cycOZONGzeybt06Hnrooe2vrVu3jr333pstW7ZsHzoaoF27dqxbt26HYx1wwAEsXbqUxYsXA/CnP/2JY445pkE/W6aHq1aJICbjxoUOZ//4R/Wvq+exSP2NHj2aU045ZXsVUWLY5gMPPJCuXbsyZMiQWt9/6KGH8s1vfpN+/fqxxx57MGjQoO2v3XDDDRx22GF07tyZww47bPvFf9SoUVxwwQVMnTp1eyMxQKtWrbj77rs544wzKC8vZ9CgQYwdO7ZBP1diLuW+ffvSpk2bSsNVz5o1i2bNmnHwwQczdOhQZsyYwU033USLFi1o27ZtWiaw0aBzMVq1KoxNtHXrjq917x4mwRHJBRp0Lrdo0Lks0rEjTJiw43b1PBaRbKJEELMbb4STT6543lSzNYmIpEptBE3ggQdgwAD4/HNYuBBat850RCL15+6YWabDkDo0pLpfJYIm0KIFTJ0a2gRuuinT0YjUX6tWrVi1alWDLjLSdNydVatW0apVq3q9L9YSgZmdCPwWaA7c6e4/r2afM4FJgAOvuftZccaUKccfH8Yg+tnPQv+C7t0zHZFI6oqKiigtLaWspgk4JGu0atWKoqKier0ntruGzKw58DbwVaAUmA2MdveFSfv0Ah4Ajnf3z8xsD3dfUdtxc+muoarefx8OPBBOOgmS7kITEYldpu4aGgwsdvcl7r4ZmAGMrLLPBcCt7v4ZQF1JINd16xY6kv3v/0IaRrEVEUmLOBNBF+CDpOel0bZk+wP7m9m/zey/UVXSDszsQjObY2Zzcr1o+v3vw777wqWXwpYtmY5GRCTzjcU7Ab2AY4HRwB1mtlvVndx9mrsXu3tx586dmzbCNGvVKozV8uab8LvfaUA6Ecm8OBuLPwS6Jj0virYlKwVecvctwHtm9jYhMcyOMa6MGz48tBNcey2YwcaNYbsGpBORTIizRDAb6GVmPc2sJTAKeLDKPjMJpQHMrBOhqmhJjDFlBbNQKti0qSIJJGhAOhFparElAncvBy4GHgfeBB5w9wVmdr2ZJQYBfxxYZWYLgVnAVe6+Kq6YskmvXjW/pgHpRKQpadC5DOrWDT74YMftGpBORNJNg85lqZ/9DFq2rLxNA9KJSFNTIsigkhK46y6IJjKia1cNSCciTU+JIMO+9S34739DA/JZZykJiEjTUyLIAv37hwTw299W32YgIhInJYIsceONsG0bTJyY6UhEpNAoEWSJ7t3hkkvg3nvh9dczHY2IFBIlgizywx9C+/bVT28pIhIXJYIs0qEDXHMNPPooPPNMpqMRkUKhRJBlLrkEiorg6qshx/r6iUiOUiLIMq1bww03wOzZ8Ne/ZjoaESkESgRZ6Oyz4ZBDQpvBvfdqmGoRiZcSQRZq3hx+/nN491244IIwPLV7xTDVSgYikk5KBFlq6NAw9ETVWcw0TLWIpJsSQZYygy++qP41DVMtIumkRJDFunevfnu3bk0bh4jkNyWCLDZ5cpjjOJmGqRaRdFMiyGIlJXDnndCuXXi+994aplpE0k+JIMuVlMCSJWHoiYEDlQREJP2UCHJAp07hTqGHH4ann850NCKSb5QIcsSll4ZG4iuvDMNVi4ikixJBjmjVKsxx/Oqr6lAmIumlRJBDRo2C4uIw9MTGjZmORkTyhRJBDmnWDKZMgdJSuPnmTEcjIvlCiSDHHHMMjBwZqolWrMh0NCKSD2JNBGZ2opm9ZWaLzWyHebfMbIyZlZnZvGg5P8548sUvfhHGHPrJTzIdiYjkg9gSgZk1B24FhgK9gdFm1ruaXe939/7Rcmdc8eSTAw6AsWPhD3+ARYsyHY2I5Lo4SwSDgcXuvsTdNwMzgJExfl5BmTgxDDdRUqL5CkSkceJMBF2AD5Kel0bbqjrNzOab2d/MrGt1BzKzC81sjpnNKSsriyPWnNO5cxiq+pVXNF+BiDROphuLHwJ6uHtf4Eng3up2cvdp7l7s7sWdO3du0gCz2X/+s+M2zVcgIvUVZyL4EEj+hl8UbdvO3Ve5e2LU/TuBgTHGk3dKS6vfrvkKRKQ+4kwEs4FeZtbTzFoCo4AHk3cws72Tno4A3owxnrxT07wEmq9AROojtkTg7uXAxcDjhAv8A+6+wMyuN7MR0W6XmtkCM3sNuBQYE1c8+Wjy5NBgnEzzFYhIfZm7ZzqGeikuLvY5c+ZkOoysMX16aBNYtiw8/+lP4ZprMhuTiGQfM5vr7sXVvZbpxmJppJISWLoUVq4Mw1U/8ohGJxWR+lEiyBMdO8Ivfwn//jf88Y+ZjkZEcokSQR4591wYMgSuugo+/TTT0YhIrlAiyCPNmsFtt8Fnn4WhqkVEUqFEkGf69g2zmU2bBi+9lOloRCQXKBHkoUmTYO+94Xvfg61bMx2NiGQ7JYI81L49/OY3YRyi22/PdDQiku2UCPLUGWfAV78a+hh88kmmoxGRbKZEkKfM4JZb4PPPYb/9NEy1iNRsp0wHIPGZPTs8fv55eEwMUw2hI5qICKhEkNeuvRbKyytv0zDVIlKVEkEeq2k4ag1TLSLJlAjymIapFpFUKBHkseqGqQa46KKmj0VEspcSQR4rKQk9jLt3D3cRdekCbdvCX/4CX3xR9/tFpDAoEeS5xDDV27aFqS3vuw9efVUNxiJSQYmgwIwcCePGwa9+BU88keloRCQbKBEUoF/9Cnr3hnPOgRUrMh2NiGSaEkEBat06tBOsXg3nnQc5NlupiKSZEkGB6tsXbropTG15yy2ZjkZEMkmJoIBdfDGcdFKY0WzOnExHIyKZklIiMLNdzKxZtL6/mY0wsxbxhiZxM4O77w5zF5x0EixenOmIRCQTUi0RPAe0MrMuwBPA2cA9cQUlTefJJ2HzZigrg4MOClNdikhhSTURmLtvAE4FbnP3M4CD4wtLmsL06WE00o8+Cs/Ly+GSS+CuuzIbl4g0rZQTgZkdAZQAj0TbmqfwphPN7C0zW2xmE2rZ7zQzczMrTjEeSYNrrw2jkSbbti20HWzZkpmYRKTppZoILgeuAf7u7gvMbF9gVm1vMLPmwK3AUKA3MNrMelezXzvgMkBTrTexmkYh3bQJvvMd3VYqUihSSgTu/qy7j3D3X0SNxivd/dI63jYYWOzuS9x9MzADGFnNfjcAvwA21SdwabyaRiHddVf405/gmmuaNh4RyYxU7xr6s5m1N7NdgDeAhWZ2VR1v6wJ8kPS8NNqWfNxDga7u/gi1MLMLzWyOmc0pKytLJWRJQXWjk7ZpE/oVjBsHv/gFTJ2amdhEpOmkWjXU293XAicDjwE9CXcONVhUsvg18P269nX3ae5e7O7FnTt3bszHSpKqo5N27x6ef+tb8LvfwSmnwOWXwwMPZDpSEYlTqnMWt4j6DZwM3OLuW8ysrhrkD4GuSc+Lom0J7YA+wDNmBrAX8KCZjXB3dW9qIiUl1c9f3Lx5uKvoa18LiaFZMzj99KaPT0Til2qJ4A/AUmAX4Dkz6w6sreM9s4FeZtbTzFoCo4AHEy+6+xp37+TuPdy9B/BfQEkgi7RuDQ89BIcdBmeeCb//faYjEpE4pNpYPNXdu7j7SR4sA46r4z3lwMXA48CbwAPRHUfXm9mIRkcuTWK33cJw1cOHw/e+B5Mm6W4ikXyTUtWQme0KTASOjjY9C1wPrKntfe7+KPBolW0/rmHfY1OJRZpe69bwf/8H3/0u/OQnsHx5aFBuXmdPEhHJBalWDf0PsA44M1rWAnfHFZRkh+nToUeP0D6w335w3HEwYQLcfnuoKtqkG35F8kKqieBL7j4x6hOwxN1/AuwbZ2CSWYnhJ5YtC1VBy5aFEkGfPvCb34QSwtChsKbWMqGI5IJU7xraaGZfdvcXAMxsCLAxvrAk06obfmLDhrB96VLYYw8491w49lh47DHYa69MRCki6ZBqIhgL/DFqKwD4DDg3npAkG9Q0/ERi+1lnQYcOcNpp4a6iv/wFjjyy6eITkfRJ9a6h19y9H9AX6OvuA4DjY41MMqqm4SeSt594Ijz7bGg0PvpouOEG2Lq1aeITkfSp1wxl7r426mEMcEUM8UiWqGn4icmTK28rLoZXXw2Nxz/+MZxwApSWNl2cItJ4jZmq0tIWhWSdmoafqK4X8q67hsble+4JU1726wczZzZ1xCLSUI1JBOpWlOdKSkLD8LZt4bG6JJBgFhqPX30VevYM4xSNGwcbdUuBSNarNRGY2TozW1vNsg7Yp4lilBzSqxe8+CJceWXobzBoEMydm+moRKQ2tSYCd2/n7u2rWdq5e6p3HEmBadkSbroJHn8cVq4M7QgjRsBLmnpIJCs1pmpIClxyz+MePcLzZF/7GixaFO4m+ve/4fDDw7bnnstEtCJSEyUCaZDqeh5feOGOyWC33eBHPwqv33QTzJ8PxxwTbjd94gkNYCeSDZQIpEFq63lcnbZtQ7vBe++FSW/eew++/nUYPBiefDL+eEWkZkoE0iB19TyuSevWcPHF8O67cMcdsGpVqC76xjfg7bfTH6eI1E2JQBoklZ7HtWnZEs4/H958M8yN/OyzcPDBcMUVsHp12sIUkRQoEUiDpNrzuC477wxXXw3vvANjxsDNN4dbUG+/HcrL0xWtiNRGiUAapD49j1Ox556hqmjuXOjdO3RGGzAAnnoqvXGLyI7Mc+y2jeLiYp8zR9Ma5zP3MN/BlVeGHs39+oXSwllnheGvRaT+zGyuuxdX95pKBBKbuvoZ1MQsDG/95ptw222hPWH8eOjSBU4+OYxjtHlzfHGLFBolAolFqv0MatOqVagievlleOONkAxeeimMY9SlC1x2WahKyrFCrUjWUdWQxKJHj3Dxr6p791Dd01Dl5aEj2j33wD/+EUoGXbuG20+/8Y0wr/LOOzf8+CL5qraqISUCiUWzZtV/UzcLo5mmw6efwt//Dg89FDqlbdgAu+wSOqp94xswbBh07pyezxLJdUoE0uTiKhHUZONGmDULHnwQHn4YPvwwJJ3DDoOhQ8MycGBIUCKFSI3F0uTS1c8gVa1bw0knhf4HH3wQ2g4mTgxTZ06aFIay2HNP+Na3QjtFWVk8cYjExT2+qWBjLRGY2YnAb4HmwJ3u/vMqr48FLgK2AuuBC919YW3HVIkgd0yfHsYeev/90ON48uSG9zNojLKy0K7wz3+GobHLykJpobg4tCkMGhTWE30iRJqaO6xfH6Z5/eCDsLz/fsV6YrnlFvj2txv2GRmpGjKz5sDbwFeBUmA2MDr5Qm9m7RNzIJvZCOB77n5ibcdVIsgfmUgU27bBK6/AY4+FxDB7NmzZEl7r1CkkhMQyaBDso+mXpAHKy2HtWvjsszBkSmJZuRKWL4dPPqm8LF++4yCOZrD33uFmiMRy5plhOPeGqC0RxDm5zGBgsbsviYKYAYwEtieCRBKI7IKmvywYidtLE3/8idtLId5k0KxZxYX+uuvgiy/g9dfDXMuzZ4fHn/2sogi+xx6hQ1v//uGxXz844ABo0SK+GCU3rFwJCxaE5Y03wuN774UL/rp1tb+3Y0fYa6+wHHlkqLbcc08oKqq46O+zT+hD0xTiLBGcDpzo7udHz88GDnP3i6vsdxFwBdASON7d36nmWBcCFwJ069Zt4LLqWiElpzR1Y3J9bNgA8+aFpDBvXlgWLKjoxNayJfTpU5EU9tsvjI/0pS+Fu5Yk923dGi70Vb+5l5bCwoXh72H58or927cPgyb26gUdOoR5OBLL7rtXrHfoEC74mfgikamqoZQSQdL+ZwFfd/dzazuuqobyQ1PcXppOW7bAW2/Ba6+FxPDaa2GSneSLAYRvccmJoUePUO3VvXso5jdvnonoBUIiLysLv7MVK8JjdeuffBL2q+7vsF07OOigcNFPLH36hA6O2d6+lKmqoQ+BrknPi6JtNZkB/D7GeCSLdOtWfYkg1WGsm1qLFuEfvk+fylVXa9eGuRXeeQcWL654fOSRcEFJttNOoejfvXtYiorCt8M99qj82KGDbnNNtnlzqGv/9NOwrFsXqvQ2b95x+eKL8DtZsSJczFesqFhqGt68VauKqpmuXUPbUKLaJnnZc88wwVI+ijMRzAZ6mVlPQgIYBZyVvIOZ9UqqChoG7FAtJPlp8uTKbQQQ7+2lcWnfPoySOmDAjq+tXx/u9Fi2rPLy/vuhz8NHH1V/O2Dz5qHhukOH8A20bduwJNYTj61bh4tYq1ahN3XyY/LSunXFvonHOKsmysvDxXrtWlizJjxWXd+wIfT9qG7ZsKHyhf/zz+v3+Wbh/O2xR+hQ2L9/WE88T066iYt7tn+bj1tsicDdy83sYuBxwu2j/+PuC8zsemCOuz8IXGxmXwG2AJ8BtVYLSf5IfKuu7a6hbLn9tKHatg3VCAcdVP3r27aFC12iaiLxzTVRTbF6dUgm69aFmdwS6+vX73iHSX01axYSTvKSvG2nncLSokX1j9u2hYv2pk0VF/DEeqr3urdsWZGkkpc2bUKV2oABIRnuvnvlx/btQ8Jr2bJiSX7epo2q4OpLPYslK1W9qwjCP3hj5jzIJ1u3hmqQTZvCUnU9cWFOXJyrXrA3bQrHSF62batYLy+vWLZs2XHdrPqSRuKxXbtwwW7fHnbdtfJ6u3a6WGeChpiQnJPNdxWJ5CINMSE55/3367ddRBpOiUCyUk13D2XrXUUiuUyJQLJSXYPWNXT2MxHZkRKBZKWSktAwnBgIrnv3iobidMx+JiIV1FgsOUcNySL1p8ZiyStqSBZJLyUCyTmpNCSrDUEkdUoEknNSaUhWG4JI6pQIJOfU1pAMYViKqkMwbNgQtovIjtRYLHkn14a4FmkKaiyWgqLOaCL1o0QgeaeuNgRQY7JIMiUCyTt1tSGoMVmkMrURSMFRhzQpRGojEEmiDmkilSkRSMFRhzSRypQIpOCoQ5pIZUoEUnDUIU2kMiUCKUglJaFheNu28Jg8D3IqbQiqOpJ8okQgUkVdbQiqOpJ8o0QgUkVdbQiqOpJ8o0QgUkVdbQh1VR2p2khyzU6ZDkAkG5WUVG43SNatW/Ud0rp1q6g2SpQYEtVGiWOKZKNYSwRmdqKZvWVmi81sQjWvX2FmC81svpk9ZWbd44xHJB1qqzpStZHkotgSgZk1B24FhgK9gdFm1rvKbq8Cxe7eF/gb8Mu44hFJl9qqjnTHkeSiOKuGBgOL3X0JgJnNAEYCCxM7uPuspP3/C3wrxnhE0qamqqPaqo1AVUeSneKsGuoCfJD0vDTaVpPvAI/FGI9I7HTHkeSirLhryMy+BRQDN9Xw+oVmNsfM5pSVlTVtcCL10Ng7jkBVR9L04qwa+hDomvS8KNpWiZl9BbgWOMbdv6juQO4+DZgGYRjq9Icqkj4NveMIVHUkmRFniWA20MvMeppZS2AU8GDyDmY2APgDMMLdV8QYi0hWUNWRZKPYEoG7lwMXA48DbwIPuPsCM7vezEZEu90EtAX+ambzzOzBGg4nkhdUdSTZSDOUiWSRumZPq1p1BKFEkZxMRKqjGcpEckQ6qo5UYpD6UiIQySLpGOdII6NKfalqSCSH1FV1VNfrUrhUNSSSJ+qqOtLIqNIQSgQiOaSuqqPaJtVRtZHURIlAJMfUNs1mY0dGVYmhMCkRiOSRxoyMqhJD4VIiEMkzNZUY6pqLWSWGwqVEIFIg0tHQrBJDflIiECkQjWloBpUY8pkSgUgBaWhDM6jEkM+UCEQEUImhkCkRiMh2KjEUJiUCEUlJ3CUGlRYyR4lARFIWV4khldKCEkV8lAhEJC0aU2JIpbSgaqX4KBGISNo0tMRQV/uCGqLjpUQgIk2ithJDXe0LaoiOlxKBiDSZmkoMdbUv6NbVeCkRiEjG1dW+0BS3rhZyotAMZSKSE6ZPD9/w338/lAQmT65IFI2duS2RKJJLFW3aVE5GuU4zlIlIzouzs1uh93FQIhCRnNfYzm6F3sdBiUBE8kJjSgxx93HI9kShRCAiea8xjdHpqFbK9ltbY00EZnaimb1lZovNbEI1rx9tZq+YWbmZnR5nLCJS2GorMcTZxyEXbm2NLRGYWXPgVmAo0BsYbWa9q+z2PjAG+HNccYiIpCKuPg65cGtrnCWCwcBid1/i7puBGcDI5B3cfam7zwe2xRiHiEiDNbaPQzpGZY27ainORNAF+CDpeWm0rd7M7EIzm2Nmc8rKytISnIhIqhparQTx39qaDjnRWOzu09y92N2LO3funOlwREQqaUyiaGzVUjrEmQg+BLomPS+KtomIFJS4bm1NlzgTwWygl5n1NLOWwCjgwRg/T0Qk5zS2aikdYksE7l4OXAw8DrwJPODuC8zsejMbAWBmg8ysFDgD+IOZLYgrHhGRbNWYqqV00KBzIiIFQIPOiYhIjZQIREQKnBKBiEiBUyIQESlwSgQiIgUu5+4aMrMyoJpJ5wDoBKxswnDqK5vjU2wNo9gaRrE1TGNi6+7u1Q7NkHOJoDZmNqem26OyQTbHp9gaRrE1jGJrmLhiU9WQiEiBUyIQESlw+ZYIpmU6gDpkc3yKrWEUW8MotoaJJba8aiMQEZH6y7cSgYiI1JMSgYhIgcubRGBmJ5rZW2a22MwmZDqeZGa21MxeN7N5ZpbRoVPN7H/MbIWZvZG0rYOZPWlm70SPu2dRbJPM7MPo3M0zs5MyFFtXM5tlZgvNbIGZXRZtz/i5qyW2jJ87M2tlZi+b2WtRbD+Jtvc0s5ei/9f7ozlLsiW2e8zsvaTz1r+pY0uKsbmZvWpmD0fP4zlv7p7zC9AceBfYF2gJvAb0znRcSfEtBTplOo4olqOBQ4E3krb9EpgQrU8AfpFFsU0CrsyC87Y3cGi03g54G+idDeeultgyfu4AA9pG6y2Al4DDgQeAUdH224FxWRTbPcDpmf6bi+K6Avgz8HD0PJbzli8lgsHAYndf4u6bgRnAyAzHlJXc/Tng0yqbRwL3Ruv3Aic3ZUwJNcSWFdz9Y3d/JVpfR5hsqQtZcO5qiS3jPFgfPW0RLQ4cD/wt2p6p81ZTbFnBzIqAYcCd0XMjpvOWL4mgC/BB0vNSsuQfIeLAE2Y218wuzHQw1djT3T+O1j8B9sxkMNW42MzmR1VHGam2SmZmPYABhG+QWXXuqsQGWXDuouqNecAK4ElC6X21h1kMIYP/r1Vjc/fEeZscnbffmNnOmYgNuBm4GtgWPe9ITOctXxJBtvuyux8KDAUuMrOjMx1QTTyUObPmWxHwe+BLQH/gY+BXmQzGzNoC/wtc7u5rk1/L9LmrJrasOHfuvtXd+wNFhNL7gZmIozpVYzOzPsA1hBgHAR2AHzR1XGY2HFjh7nOb4vPyJRF8CHRNel4UbcsK7v5h9LgC+DvhnyGbLDezvQGixxUZjmc7d18e/bNuA+4gg+fOzFoQLrTT3f3/os1Zce6qiy2bzl0Uz2pgFnAEsJuZ7RS9lPH/16TYToyq2tzdvwDuJjPnbQgwwsyWEqq6jwd+S0znLV8SwWygV9Si3hIYBTyY4ZgAMLNdzKxdYh34GvBG7e9qcg8C50br5wL/yGAslSQuspFTyNC5i+pn7wLedPdfJ72U8XNXU2zZcO7MrLOZ7Rattwa+SmjDmAWcHu2WqfNWXWyLkhK7Eergm/y8ufs17l7k7j0I17On3b2EuM5bplvF07UAJxHulngXuDbT8STFtS/hLqbXgAWZjg34C6GaYAuhjvE7hLrHp4B3gH8BHbIotj8BrwPzCRfdvTMU25cJ1T7zgXnRclI2nLtaYsv4uQP6Aq9GMbwB/Djavi/wMrAY+CuwcxbF9nR03t4A7iO6syhTC3AsFXcNxXLeNMSEiEiBy5eqIRERaSAlAhGRAqdEICJS4JQIREQKnBKBiEiBUyIQiZjZ1qQRJ+dZGkexNbMeyaOqimSTnereRaRgbPQw3IBIQVGJQKQOFuaT+KWFOSVeNrP9ou09zOzpaHCyp8ysW7R9TzP7ezTO/WtmdmR0qOZmdkc09v0TUW9WzOzSaC6B+WY2I0M/phQwJQKRCq2rVA19M+m1Ne5+CHALYVRIgN8B97p7X2A6MDXaPhV41t37EeZXWBBt7wXc6u4HA6uB06LtE4AB0XHGxvOjidRMPYtFIma23t3bVrN9KXC8uy+JBnf7xN07mtlKwrANW6LtH7t7JzMrA4o8DFqWOEYPwjDHvaLnPwBauPuNZvZPYD0wE5jpFWPkizQJlQhEUuM1rNfHF0nrW6looxsG3EooPcxOGl1SpEkoEYik5ptJj/+J1l8kjAwJUAI8H60/BYyD7ROf7FrTQc2sGdDV3WcRxr3fFdihVCISJ33zEKnQOpqtKuGf7p64hXR3M5tP+FY/Otp2CXC3mV0FlAHfjrZfBkwzs+8QvvmPI4yqWp3mwH1RsjBgqoex8UWajNoIROoQtREUu/vKTMciEgdVDYmIFDiVCERECpxKBCIiBU6JQESkwCkRiIgUOCUCEZECp0QgIlLg/h+L774cxiw46wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-23T07:22:10.749404Z",
     "iopub.status.busy": "2020-09-23T07:22:10.742226Z",
     "iopub.status.idle": "2020-09-23T07:22:10.887415Z",
     "shell.execute_reply": "2020-09-23T07:22:10.888043Z"
    },
    "id": "6hXx-xOv-llh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFEmZ5zq-llk"
   },
   "source": [
    "이 그래프에서 점선은 훈련 손실과 훈련 정확도를 나타냅니다. 실선은 검증 손실과 검증 정확도입니다.\n",
    "\n",
    "훈련 손실은 에포크마다 *감소*하고 훈련 정확도는 *증가*한다는 것을 주목하세요. 경사 하강법 최적화를 사용할 때 볼 수 있는 현상입니다. 매 반복마다 최적화 대상의 값을 최소화합니다.\n",
    "\n",
    "하지만 검증 손실과 검증 정확도에서는 그렇지 못합니다. 약 20번째 에포크 이후가 최적점인 것 같습니다. 이는 과대적합 때문입니다. 이전에 본 적 없는 데이터보다 훈련 데이터에서 더 잘 동작합니다. 이 지점부터는 모델이 과도하게 최적화되어 테스트 데이터에서 *일반화*되기 어려운 훈련 데이터의 특정 표현을 학습합니다.\n",
    "\n",
    "여기에서는 과대적합을 막기 위해 단순히 20번째 에포크 근처에서 훈련을 멈출 수 있습니다. 나중에 콜백(callback)을 사용하여 자동으로 이렇게 하는 방법을 배워 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('Basic_text_classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "84d56173b818a73ea5c6160e46ed9fcb20e40f19d976849eaf324bfd63c96975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
